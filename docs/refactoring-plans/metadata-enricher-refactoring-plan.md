# ğŸ”§ MetadataEnricher ë¦¬íŒ©í† ë§ ê³„íšì„œ

**ì‘ì„±ì¼**: 2025-10-12
**ë‹´ë‹¹**: 8ì¸ í˜ë¥´ì†Œë‚˜ (Planning/Taskmaster/Review í”„ë¡œí† ì½œ ì¤€ìˆ˜)
**ëŒ€ìƒ**: `src/anivault/services/metadata_enricher.py` (874 lines)
**ëª©í‘œ**: 874 lines â†’ 300 lines (65% ê°ì†Œ), Strategy íŒ¨í„´ ì ìš©
**ë¸Œëœì¹˜**: `feature/refactor-metadata-enricher`
**Task Master íƒœê·¸**: `feature-refactor-metadata-enricher`

---

## ğŸ“Š Executive Summary

### í˜„í™©
- **í˜„ì¬ ë¼ì¸ ìˆ˜**: 874 lines (ì‹¤ì¸¡, 2025-10-12)
- **ë¬¸ì œì **:
  - Single Responsibility ìœ„ë°˜ (fetching, scoring, transforming, batching í˜¼ì¬)
  - í…ŒìŠ¤íŠ¸ ì–´ë ¤ì›€ (ê±°ëŒ€í•œ í´ë˜ìŠ¤)
  - ë§¤ì¹­ ê·¼ê±° ë¶ˆíˆ¬ëª… (ì‚¬ìš©ìê°€ "ì™œ ì´ ë§¤ì¹­?"ì„ ëª¨ë¦„)
  - í™•ì¥ ì–´ë ¤ì›€ (scorer ì¶”ê°€ ì‹œ ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • í•„ìš”)

### ëª©í‘œ
- **ëª©í‘œ ë¼ì¸ ìˆ˜**: 300 lines (Facade)
- **íŒ¨í„´**: Strategy (scorers) + Facade (enricher)
- **ëª¨ë“ˆ ë¶„ë¦¬**: 9ê°œ íŒŒì¼ (1 â†’ 9)
- **í…ŒìŠ¤íŠ¸**: 80%+ ì»¤ë²„ë¦¬ì§€, íšŒê·€ 0ê°œ
- **ì„±ëŠ¥**: â‰¤5% ì˜¤ë²„í—¤ë“œ

### ì„±ê³µ ì§€í‘œ
| ì§€í‘œ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|------|------|-----------|
| ë¼ì¸ ê°ì†Œ | 65% (874â†’300) | wc -l |
| í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ | 80%+ | pytest --cov |
| API í˜¸í™˜ì„± | 100% | ê¸°ì¡´ í…ŒìŠ¤íŠ¸ í†µê³¼ |
| ì„±ëŠ¥ ì˜¤ë²„í—¤ë“œ | â‰¤5% | í”„ë¡œíŒŒì¼ë§ ìŠ¤í¬ë¦½íŠ¸ |
| íƒ€ì… ì»¤ë²„ë¦¬ì§€ | 100% | mypy strict |
| Match Evidence | ëª¨ë“  ê²°ê³¼ | í†µí•© í…ŒìŠ¤íŠ¸ ê²€ì¦ |

---

## ğŸ­ Phase ê²°ê³¼ ìš”ì•½

### Planning Protocol (ì™„ë£Œ âœ…)

| Phase | ì‚°ì¶œë¬¼ | ê²°ê³¼ | ìƒíƒœ |
|-------|--------|------|------|
| **Phase 0** | Kickoff | ëª©í‘œ ìˆ˜ë¦½ | âœ… |
| **Phase 1** | ìš”êµ¬ì‚¬í•­ (Evidence Log) | 8ê°œ ì¦ê±° ìˆ˜ì§‘ | âœ… |
| **Phase 2** | ì„¤ê³„ (Tradeoff) | ì˜µì…˜ B (ìˆ˜ì§ ë¶„í• ) ì„ íƒ | âœ… |
| **Phase 3** | ìœ„í—˜ ë¶„ì„ (Risks) | 6ê°œ ìœ„í—˜ ì‹ë³„ ë° ì™„í™”ì±… | âœ… |
| **Phase 4** | ì‘ì—… ë¶„í•´ (Mini WBS) | 14ê°œ ì‘ì—… í•­ëª© | âœ… |
| **Phase 5** | ìµœì¢… ë¦¬ë·° (Consensus) | 8ì¸ ìŠ¹ì¸ (7ì°¬ì„±, 1ì¡°ê±´ë¶€) | âœ… |

### Taskmaster Workflow (ì™„ë£Œ âœ…)

| Phase | ì‚°ì¶œë¬¼ | ê²°ê³¼ | ìƒíƒœ |
|-------|--------|------|------|
| **Phase 0** | í˜„ì¬ ìƒíƒœ í™•ì¸ | 9ê°œ ê¸°ì¡´ íƒœê·¸ í™•ì¸ | âœ… |
| **Phase 1** | íƒœê·¸ ìƒì„± | feature-refactor-metadata-enricher | âœ… |
| **Phase 2** | PRD ì‘ì„± | 830 words, êµ¬ì¡°í™” ì™„ë£Œ | âœ… |
| **Phase 3** | íƒœìŠ¤í¬ íŒŒì‹± | 10 tasks ìƒì„± | âœ… |
| **Phase 4** | ë³µì¡ë„ ë¶„ì„ | 5 tasks í™•ì¥ í•„ìš” (7+) | âœ… |
| **Phase 5** | ì„œë¸ŒíƒœìŠ¤í¬ í™•ì¥ | 27 subtasks ìƒì„± | âœ… |
| **Phase 6** | ê²€ì¦ | ì˜ì¡´ì„± ê²€ì¦ í†µê³¼ | âœ… |

### Review Protocol (ì™„ë£Œ âœ…)

| Phase | ê²€í†  í•­ëª© | ê²°ê³¼ | ìƒíƒœ |
|-------|-----------|------|------|
| **Phase 0** | PRD-Task ë§¤ì¹­ | 100% (10/10) | âœ… |
| **Phase 1** | ì½”ë“œ í’ˆì§ˆ | ëª¨í˜¸ì„± 4ê±´ ì‹ë³„ | âœ… |
| **Phase 2** | ëª…í™•ì„± ê²€ì¦ | 86% â†’ 100% ê°œì„  | âœ… |
| **Phase 3** | ë³´ì•ˆ ê°ì‚¬ | API í‚¤ ë§ˆìŠ¤í‚¹ ì¶”ê°€ | âœ… |
| **Phase 4** | UX ê²€ì¦ | Match Evidence íˆ¬ëª…ì„± í™•ë³´ | âœ… |
| **Phase 5** | ìµœì¢… ìŠ¹ì¸ | 8/8 ì°¬ì„± | âœ… |

---

## ğŸ—ï¸ ìµœì¢… ì•„í‚¤í…ì²˜

### Before (Current)
```
src/anivault/services/
â””â”€â”€ metadata_enricher.py (874 lines)
    â”œâ”€â”€ EnrichedMetadata dataclass
    â”œâ”€â”€ MetadataEnricher class
    â”‚   â”œâ”€â”€ enrich_metadata() - async
    â”‚   â”œâ”€â”€ enrich_batch() - async
    â”‚   â”œâ”€â”€ _find_best_match() - scoring
    â”‚   â”œâ”€â”€ _calculate_match_score() - scoring
    â”‚   â”œâ”€â”€ _calculate_title_similarity() - scoring
    â”‚   â””â”€â”€ ... (10+ methods)
    â””â”€â”€ Tests: tests/test_metadata_constants.pyë§Œ ì¡´ì¬
```

**ë¬¸ì œì **:
- 11ê°œ ë©”ì„œë“œê°€ í•œ í´ë˜ìŠ¤ì— ì§‘ì¤‘
- í…ŒìŠ¤íŠ¸ ì–´ë ¤ì›€ (ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë¶ˆê°€ëŠ¥)
- ë§¤ì¹­ ë¡œì§ ë¸”ë™ë°•ìŠ¤ (ê·¼ê±° ì—†ìŒ)

### After (Target)
```
src/anivault/services/metadata_enricher/
â”œâ”€â”€ __init__.py                          # Public API exports
â”œâ”€â”€ enricher.py                          # Facade (200 lines) â¬…ï¸ -674 lines
â”‚   â””â”€â”€ MetadataEnricher (orchestration only)
â”‚
â”œâ”€â”€ models.py                            # Data models (50 lines)
â”‚   â”œâ”€â”€ ScoreResult
â”‚   â””â”€â”€ MatchEvidence
â”‚
â”œâ”€â”€ scoring/                             # Strategy Pattern
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_scorer.py                   # Protocol (50 lines)
â”‚   â”œâ”€â”€ engine.py                        # ScoringEngine (100 lines)
â”‚   â”œâ”€â”€ title_scorer.py                  # Title similarity (100 lines)
â”‚   â”œâ”€â”€ year_scorer.py                   # Year bonus (50 lines)
â”‚   â””â”€â”€ media_type_scorer.py             # Media type bonus (50 lines)
â”‚
â”œâ”€â”€ fetcher.py                           # TMDB API calls (150 lines)
â”‚   â””â”€â”€ TMDBMetadataFetcher
â”‚
â”œâ”€â”€ transformer.py                       # Data conversion (100 lines)
â”‚   â””â”€â”€ MetadataTransformer
â”‚       â”œâ”€â”€ to_file_metadata()
â”‚       â”œâ”€â”€ _extract_genres()
â”‚       â”œâ”€â”€ _parse_year()
â”‚       â”œâ”€â”€ _extract_basic_info()
â”‚       â””â”€â”€ _normalize_media_type()
â”‚
â””â”€â”€ batch_processor.py                   # Batch processing (100 lines)
    â””â”€â”€ BatchProcessor
        â””â”€â”€ process() -> BatchResult

tests/services/
â”œâ”€â”€ scoring/
â”‚   â”œâ”€â”€ test_models.py
â”‚   â”œâ”€â”€ test_title_scorer.py
â”‚   â”œâ”€â”€ test_year_scorer.py
â”‚   â”œâ”€â”€ test_media_type_scorer.py
â”‚   â””â”€â”€ test_engine.py
â”œâ”€â”€ test_tmdb_fetcher.py
â”œâ”€â”€ test_metadata_transformer.py
â”œâ”€â”€ test_batch_processor.py
â””â”€â”€ integration/
    â””â”€â”€ test_enrichment_flow.py
```

**ê°œì„ ì **:
- 9ê°œ ëª¨ë“ˆë¡œ ë¶„ë¦¬ (ê° 50-200 lines)
- ê° ëª¨ë“ˆ ë…ë¦½ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
- MatchEvidenceë¡œ ê·¼ê±° ì œê³µ
- scorer ì¶”ê°€ ì‹œ ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • ë¶ˆí•„ìš”

### ëª¨ë“ˆ ì˜ì¡´ì„± (Unidirectional)
```
enricher.py (Facade)
  â†“ uses
fetcher.py, transformer.py, batch_processor.py
  â†“ uses
scoring/engine.py
  â†“ uses
scoring/title_scorer.py, year_scorer.py, media_type_scorer.py
  â†“ implements
scoring/base_scorer.py (Protocol)
  â†“ uses
models.py (ScoreResult, MatchEvidence)
```

---

## ğŸ“‹ Task Master íƒœìŠ¤í¬ ëª©ë¡

### 10ê°œ ë©”ì¸ íƒœìŠ¤í¬

| ID | Title | Priority | Dependencies | Complexity | Subtasks |
|----|-------|----------|--------------|------------|----------|
| 1 | ìŠ¤ì½”ì–´ë§ ëª¨ë¸ ë° í”„ë¡œí† ì½œ ë¶„ë¦¬ | High | - | 6/10 | 0 |
| 2 | TitleScorer ì „ëµ êµ¬í˜„ | High | 1 | 7/10 | **5** |
| 3 | YearScorer ì „ëµ êµ¬í˜„ | Medium | 1 | 5/10 | 0 |
| 4 | MediaTypeScorer ì „ëµ êµ¬í˜„ | Medium | 1 | 5/10 | 0 |
| 5 | ìŠ¤ì½”ì–´ë§ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ êµ¬ì„± | High | 1,2,3,4 | 8/10 | **6** |
| 6 | TMDB Fetcher ëª¨ë“ˆ ì¶”ì¶œ | High | 1 | 7/10 | **5** |
| 7 | Metadata Transformer ëª¨ë“ˆ ë¶„ë¦¬ | Medium | 6 | 6/10 | **0** |
| 8 | ë¹„ë™ê¸° ë°°ì¹˜ í”„ë¡œì„¸ì„œ ëª¨ë“ˆí™” | Medium | 6,7 | 6/10 | 0 |
| 9 | MetadataEnricher í¼ì‚¬ë“œ ì¬êµ¬ì„± | High | 2,3,4,5,6,7,8 | 9/10 | **6** |
| 10 | í†µí•© ê²€ì¦ ë° ë¬¸ì„œ/ì„±ëŠ¥ ì—…ë°ì´íŠ¸ | Medium | 9 | 7/10 | **5** |

**í†µê³„**:
- ì´ 10 tasks (High: 5, Medium: 5)
- ì´ 27 subtasks
- í‰ê·  ë³µì¡ë„: 6.7/10
- í™•ì¥ëœ íƒœìŠ¤í¬: 5ê°œ (ë³µì¡ë„ 7+)

### Task 1: ìŠ¤ì½”ì–´ë§ ëª¨ë¸ ë° í”„ë¡œí† ì½œ ë¶„ë¦¬

**ë””ë ‰í† ë¦¬**: `src/anivault/services/metadata_enricher/scoring/`

**ìƒì„± íŒŒì¼**:
- `__init__.py` - Public API exports
- `models.py` - ScoreResult, MatchEvidence dataclasses
- `base_scorer.py` - BaseScorer Protocol

**ì£¼ìš” êµ¬í˜„**:
```python
# models.py
@dataclass
class MatchEvidence:
    feature: str        # "title_similarity", "year_match", etc.
    score: float        # 0.0-1.0
    reason: str         # "High similarity: Attack on Titan vs é€²æ’ƒã®å·¨äºº"
    weight: float       # Feature weight in final score

@dataclass
class ScoreResult:
    total_score: float
    evidences: list[MatchEvidence]
    raw_scores: dict[str, float]

# base_scorer.py
class BaseScorer(Protocol):
    def score(self, file_info: ParsingResult, candidate: dict) -> ScoreResult: ...
    def supports(self, file_info: ParsingResult, candidate: dict) -> bool: ...
```

**ê²€ì¦**:
- mypy strict í†µê³¼
- Pydantic validation í™•ì¸
- ìˆœí™˜ ì°¸ì¡° ì—†ìŒ

---

### Task 2: TitleScorer ì „ëµ êµ¬í˜„ (5 subtasks)

**íŒŒì¼**: `scoring/title_scorer.py` (100 lines)

**Subtasks**:
1. âœ… `_calculate_title_similarity` ê·œì¹™ ì •ë¦¬ - ê¸°ì¡´ ë¡œì§ ë¬¸ì„œí™”
2. âœ… TitleScorer í´ë˜ìŠ¤ ì´ˆì•ˆ êµ¬í˜„ - BaseScorer ìƒì†
3. âœ… MatchEvidence ì—°ë™ ë° reason í¬ë§· ì ìš©
4. âœ… MetadataEnricher ì£¼ì… ë¦¬íŒ©í„°ë§ - DI ë°©ì‹ ì ìš©
5. âœ… TitleScorer ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì¶”ê°€ - ìœ ë‹ˆì½”ë“œ, ê²½ê³„ê°’ í…ŒìŠ¤íŠ¸

**í•µì‹¬ ë¡œì§**:
```python
class TitleScorer:
    def __init__(self, weight: float = 0.6):
        self.weight = weight

    def score(self, file_info: ParsingResult, candidate: dict) -> ScoreResult:
        # Extract from metadata_enricher.py:844-945
        similarity = self._calculate_similarity(file_info.title, candidate['title'])

        evidence = MatchEvidence(
            feature="title_similarity",
            score=similarity,
            reason=f"Title match: {file_info.title} vs {candidate['title']}",
            weight=self.weight
        )

        return ScoreResult(
            total_score=similarity * self.weight,
            evidences=[evidence],
            raw_scores={"title": similarity}
        )
```

**í…ŒìŠ¤íŠ¸**: `tests/services/scoring/test_title_scorer.py`
- ìœ ë‹ˆì½”ë“œ ì²˜ë¦¬
- ë¶€ë¶„ ì¼ì¹˜
- ë¹ˆ ë¬¸ìì—´
- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (Â±5%)

---

### Task 3: YearScorer ì „ëµ êµ¬í˜„

**íŒŒì¼**: `scoring/year_scorer.py` (50 lines)

**í•µì‹¬ ë¡œì§**:
```python
class YearScorer:
    def __init__(self, weight: float = 0.3, tolerance: int = 1):
        self.weight = weight
        self.tolerance = tolerance

    def supports(self, file_info: ParsingResult, candidate: dict) -> bool:
        return file_info.year is not None and 'year' in candidate

    def score(self, file_info: ParsingResult, candidate: dict) -> ScoreResult:
        year_diff = abs(file_info.year - candidate['year'])

        if year_diff == 0:
            score = 1.0
            reason = f"Exact year match: {file_info.year}"
        elif year_diff <= self.tolerance:
            score = 1.0 - (year_diff * 0.2)
            reason = f"Close year: {file_info.year} vs {candidate['year']} (Â±{year_diff})"
        else:
            score = 0.0
            reason = f"Year mismatch: {file_info.year} vs {candidate['year']}"

        evidence = MatchEvidence(
            feature="year_match",
            score=score,
            reason=reason,
            weight=self.weight
        )

        return ScoreResult(
            total_score=score * self.weight,
            evidences=[evidence],
            raw_scores={"year": score}
        )
```

**Extract From**: `metadata_enricher.py:760-810` (ì—°ë„ ë³´ë„ˆìŠ¤ ë¡œì§)

---

### Task 4: MediaTypeScorer ì „ëµ êµ¬í˜„

**íŒŒì¼**: `scoring/media_type_scorer.py` (50 lines)

**Extract From**: `metadata_enricher.py:785-807` (ë¯¸ë””ì–´ íƒ€ì… ë³´ë„ˆìŠ¤)

---

### Task 5: ìŠ¤ì½”ì–´ë§ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ êµ¬ì„± (6 subtasks)

**íŒŒì¼**: `scoring/engine.py` (100 lines)

**Subtasks**:
1. âœ… ê¸°ì¡´ ê°€ì¤‘ì¹˜ ê³„ì‚° íë¦„ ë¶„ì„ - `_calculate_match_score` í•´ë¶€
2. âœ… ScoreResultÂ·MatchEvidenceÂ·BaseScorer ì„¤ê³„ - ë°ì´í„° ëª¨ë¸ ì •ì˜
3. âœ… CompositeScorerÂ·ScoringEngine êµ¬í˜„ - ê°€ì¤‘ì¹˜ ì¡°í•© ì—”ì§„
4. âœ… MetadataEnricherì™€ ì„¤ì • ì—°ë™ ë¦¬íŒ©í„°ë§ - DI + config ì˜¤ë²„ë¼ì´ë“œ
5. âœ… ì˜ˆì™¸ ì²˜ë¦¬ ë° ë¡œê¹… ë³´ì¡´ ê²€ì¦ - ê¸°ì¡´ ì—ëŸ¬ íë¦„ ìœ ì§€
6. âœ… ì—”ì§„ ë° í†µí•© í…ŒìŠ¤íŠ¸ ë³´ê°• - ë‹¨ìœ„Â·í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±

**í•µì‹¬ ë¡œì§**:
```python
class ScoringEngine:
    def __init__(self, scorers: list[BaseScorer]):
        self.scorers = scorers

    def calculate(
        self,
        file_info: ParsingResult,
        candidate: dict
    ) -> ScoreResult:
        all_evidences = []
        raw_scores = {}
        total_score = 0.0

        for scorer in self.scorers:
            if scorer.supports(file_info, candidate):
                result = scorer.score(file_info, candidate)
                all_evidences.extend(result.evidences)
                raw_scores.update(result.raw_scores)
                total_score += result.total_score

        return ScoreResult(
            total_score=min(total_score, 1.0),
            evidences=all_evidences,
            raw_scores=raw_scores
        )
```

**Replace**: `metadata_enricher.py:696-843` (_calculate_match_score ì „ì²´)

---

### Task 6: TMDB Fetcher ëª¨ë“ˆ ì¶”ì¶œ (5 subtasks)

**íŒŒì¼**: `fetcher.py` (150 lines)

**Subtasks**:
1. âœ… ê¸°ì¡´ TMDB í˜¸ì¶œ ë¡œì§ ì •ë°€ ë¶„ì„ - search/details íë¦„ íŒŒì•…
2. âœ… TMDBFetcher ì„¤ê³„ ë° ê¸°ë³¸ êµ¬í˜„ - search_matches, get_details ë©”ì„œë“œ
3. âœ… TMDBClient ì˜ì¡´ì„± ì£¼ì… ê²½ë¡œ ì •ë¹„ - rate limiter/semaphore ìœ ì§€
4. âœ… MetadataEnricherê°€ Fetcherë¥¼ ì‚¬ìš©í•˜ë„ë¡ ë¦¬íŒ©í„°ë§
5. âœ… TMDBFetcher ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± - ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸, ì—ëŸ¬ ë³€í™˜

**ë³´ì•ˆ ì¶”ê°€ì‚¬í•­** (ë‹ˆì•„ ìš”ì²­):
- API í‚¤ ë¡œê¹… ë§ˆìŠ¤í‚¹ í™•ì¸
- URL íŒŒë¼ë¯¸í„° ë¯¼ê° ì •ë³´ ë…¸ì¶œ ë°©ì§€
- log_operation_error/successì™€ ì¼ê´€ì„± ìœ ì§€

**í•µì‹¬ ë©”ì„œë“œ**:
```python
class TMDBMetadataFetcher:
    def __init__(self, tmdb_client: TMDBClient):
        self.tmdb_client = tmdb_client

    async def search_matches(
        self,
        file_info: ParsingResult
    ) -> list[dict[str, Any]]:
        """Search TMDB for matching media."""
        # Extract from metadata_enricher.py:223-243
        response = await self.tmdb_client.search_media(file_info.title)
        return [r.model_dump() for r in response.results]

    async def get_details(
        self,
        tmdb_id: int,
        media_type: str
    ) -> TMDBMediaDetails:
        """Get detailed media information."""
        # Extract from metadata_enricher.py:244-330
        return await self.tmdb_client.get_media_details(tmdb_id, media_type)
```

**Extract From**: `metadata_enricher.py:223-330` (enrich_metadata ë‚´ë¶€)

---

### Task 7: Metadata Transformer ëª¨ë“ˆ ë¶„ë¦¬

**íŒŒì¼**: `transformer.py` (100 lines)

**Note**: ë³µì¡ë„ ë¶„ì„ ê²°ê³¼ 6/10ìœ¼ë¡œ í™•ì¥ threshold(7) ë¯¸ë‹¬.
ë‹¨ì¼ ë³€í™˜ ë¡œì§ì´ë¯€ë¡œ subtask ì—†ì´ ì§ì ‘ êµ¬í˜„ ê¶Œì¥.

**êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
1. ê¸°ì¡´ ë³€í™˜ ë¡œì§ ë¶„ì„ (`EnrichedMetadata.to_file_metadata`, lines 60-159)
2. `MetadataTransformer` í´ë˜ìŠ¤ ì‘ì„± ë° 4ê°œ í—¬í¼ í•¨ìˆ˜ ì¶”ì¶œ
3. ìˆœí™˜ ì˜ì¡´ì„± ë°©ì§€ (enricher â†’ transformer ë‹¨ë°©í–¥)
4. Pydantic/dict/None ê²½ë¡œ í…ŒìŠ¤íŠ¸ ì¶”ê°€

**í—¬í¼ í•¨ìˆ˜** (ë¦¬ë‚˜ ìš”ì²­ - êµ¬ì²´í™”):
```python
class MetadataTransformer:
    def to_file_metadata(
        self,
        enriched: EnrichedMetadata,
        file_path: Path
    ) -> FileMetadata:
        """Convert EnrichedMetadata to FileMetadata."""
        # Extract from metadata_enricher.py:60-159
        ...

    def _extract_genres(self, tmdb_data) -> list[str]:
        """Extract genres from TMDB data (Pydantic or dict)."""
        ...

    def _parse_year(self, date_string: str | None) -> int | None:
        """Parse year from date string (YYYY-MM-DD)."""
        ...

    def _extract_basic_info(self, tmdb_data) -> dict:
        """Extract overview, poster_path, vote_average, etc."""
        ...

    def _normalize_media_type(self, media_type: str | None) -> str | None:
        """Normalize media type to standard values."""
        ...
```

**Extract From**: `metadata_enricher.py:60-159` (EnrichedMetadata.to_file_metadata)

---

### Task 8: ë¹„ë™ê¸° ë°°ì¹˜ í”„ë¡œì„¸ì„œ ëª¨ë“ˆí™”

**íŒŒì¼**: `batch_processor.py` (100 lines)

**ë°ì´í„° êµ¬ì¡°** (ê¹€ì§€ìœ  ìš”ì²­ - êµ¬ì²´í™”):
```python
@dataclass
class BatchResult:
    enriched: list[EnrichedMetadata]   # ì„±ê³µí•œ ê²°ê³¼ë“¤
    errors: dict[str, Exception]       # {file_title: exception}
    stats: dict[str, int]              # {"total": N, "success": M, "failed": K}
```

**í•µì‹¬ ë©”ì„œë“œ**:
```python
class BatchProcessor:
    async def process(
        self,
        file_infos: list[ParsingResult],
        enrich_func: Callable
    ) -> BatchResult:
        """Process batch with error aggregation."""
        # Extract from metadata_enricher.py:425-587
        tasks = [enrich_func(fi) for fi in file_infos]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        enriched = []
        errors = {}

        for i, result in enumerate(results):
            if isinstance(result, Exception):
                errors[file_infos[i].title] = result
            else:
                enriched.append(result)

        return BatchResult(
            enriched=enriched,
            errors=errors,
            stats={
                "total": len(file_infos),
                "success": len(enriched),
                "failed": len(errors)
            }
        )
```

**Extract From**: `metadata_enricher.py:425-587` (enrich_batch)

---

### Task 9: MetadataEnricher í¼ì‚¬ë“œ ì¬êµ¬ì„± (6 subtasks - ìµœê³  ë³µì¡ë„)

**íŒŒì¼**: `enricher.py` (200 lines)

**Subtasks**:
1. âœ… ê¸°ì¡´ MetadataEnricher êµ¬ì¡° ë¶„ì„
2. âœ… DI ëŒ€ìƒ ì»´í¬ë„ŒíŠ¸ ê³„ì•½ ì •ì˜
3. âœ… í¼ì‚¬ë“œ API ë¦¬ë””ìì¸
4. âœ… enrich í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì„¤ê³„
5. âœ… í˜¸í™˜ì„± ë° ëª¨ë“ˆ ê²½ë¡œ ì „í™˜
6. âœ… í…ŒìŠ¤íŠ¸ ë° ë¬¸ì„œí™” ê³„íš

**Facade êµ¬ì¡°**:
```python
class MetadataEnricher:
    """Facade for metadata enrichment (orchestration only)."""

    def __init__(
        self,
        tmdb_client: TMDBClient | None = None,
        fetcher: TMDBMetadataFetcher | None = None,
        scoring_engine: ScoringEngine | None = None,
        transformer: MetadataTransformer | None = None,
        batch_processor: BatchProcessor | None = None,
        min_confidence: float = 0.3,
    ):
        # DI with default instances
        self.fetcher = fetcher or TMDBMetadataFetcher(tmdb_client or TMDBClient())
        self.scoring_engine = scoring_engine or self._create_default_engine()
        self.transformer = transformer or MetadataTransformer()
        self.batch_processor = batch_processor or BatchProcessor()
        self.min_confidence = min_confidence

    async def enrich_metadata(
        self,
        file_info: ParsingResult
    ) -> EnrichedMetadata:
        """Orchestrate: fetcher â†’ scorer â†’ transformer."""
        # 1. Fetch matches
        candidates = await self.fetcher.search_matches(file_info)

        # 2. Score and find best
        best_match = self._find_best_match(file_info, candidates)

        # 3. Get details if confidence high
        if best_match and best_match.total_score >= self.min_confidence:
            details = await self.fetcher.get_details(
                best_match.tmdb_id,
                best_match.media_type
            )
            return EnrichedMetadata(
                file_info=file_info,
                tmdb_data=details,
                match_confidence=best_match.total_score,
                match_evidence=best_match.evidences  # NEW!
            )
        ...

    def _create_default_engine(self) -> ScoringEngine:
        return ScoringEngine([
            TitleScorer(weight=0.6),
            YearScorer(weight=0.3),
            MediaTypeScorer(weight=0.1)
        ])
```

**API í˜¸í™˜ì„±**:
- âœ… `enrich_metadata()` ì‹œê·¸ë‹ˆì²˜ ìœ ì§€
- âœ… `enrich_batch()` ì‹œê·¸ë‹ˆì²˜ ìœ ì§€
- âœ… `enrich_metadata_sync()` ìœ ì§€
- âœ… ê¸°ì¡´ import ê²½ë¡œ ìœ ì§€ (thin wrapper)

---

### Task 10: í†µí•© ê²€ì¦ ë° ë¬¸ì„œ/ì„±ëŠ¥ ì—…ë°ì´íŠ¸ (5 subtasks)

**Subtasks**:
1. âœ… í†µí•© í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì •ë¦¬ (10+ scenarios)
2. âœ… httpx_mock í†µí•© í…ŒìŠ¤íŠ¸ êµ¬í˜„
3. âœ… ì»¤ë²„ë¦¬ì§€ ì¸¡ì • (80%+ ëª©í‘œ)
4. âœ… í”„ë¡œíŒŒì¼ë§ ì„±ëŠ¥ ë¹„êµ (Â±5%)
5. âœ… ë¬¸ì„œ ë° CI êµ¬ì„± ì—…ë°ì´íŠ¸

**í†µí•© í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
1. ì„±ê³µ: ë§¤ì¹­ + ìƒì„¸ ì •ë³´
2. ë¶€ë¶„ ì„±ê³µ: ë§¤ì¹­ë§Œ, ìƒì„¸ ì‹¤íŒ¨
3. ì‹¤íŒ¨: ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ
4. ì‹¤íŒ¨: ë‚®ì€ confidence
5. ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: ConnectionError
6. ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: TimeoutError
7. TMDB API ì˜¤ë¥˜: Rate limit
8. ë°ì´í„° ì˜¤ë¥˜: Invalid response
9. ë°°ì¹˜ ì²˜ë¦¬: ì¼ë¶€ ì„±ê³µ/ì¼ë¶€ ì‹¤íŒ¨
10. ë°°ì¹˜ ì²˜ë¦¬: ì „ì²´ ì‹¤íŒ¨

**ë¬¸ì„œ ì—…ë°ì´íŠ¸**:
- `docs/architecture/metadata-enricher.md` - ëª¨ë“ˆ ë‹¤ì´ì–´ê·¸ë¨
- `README.md` - DI ì‚¬ìš©ë²•
- `docs/dev-guide/extending-scorers.md` - Scorer ì¶”ê°€ ê°€ì´ë“œ

---

## ğŸ“… Implementation Timeline

### Phase 1: Scorer Extraction (3-4ì¼)

**Week 1, Days 1-2: ê¸°ë°˜ ì‘ì—…**
- [x] Task 1: models.py, base_scorer.py ìƒì„±
- [x] ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¤ì • (`scoring/`)
- [x] Import ê²½ë¡œ ê²€ì¦

**Week 1, Days 3-4: TitleScorer**
- [x] Task 2.1-2.2: TitleScorer êµ¬í˜„
- [x] Task 2.3-2.4: í…ŒìŠ¤íŠ¸ ë° í†µí•©
- [x] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

**ì²´í¬í¬ì¸íŠ¸**: TitleScorer ë‹¨ë… ë™ì‘ ê²€ì¦

---

### Phase 2: Year/MediaType Scorers (2ì¼)

**Week 1, Days 5-6**
- [x] Task 3: YearScorer êµ¬í˜„
- [x] Task 4: MediaTypeScorer êµ¬í˜„
- [x] Task 5.1-5.3: ScoringEngine í†µí•©
- [x] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

**ì²´í¬í¬ì¸íŠ¸**: 3ê°œ scorer í†µí•© ë™ì‘ ê²€ì¦

---

### Phase 3: Fetcher/Transformer/Batch (3-4ì¼)

**Week 2, Days 1-2: Fetcher**
- [x] Task 6.1-6.2: TMDBMetadataFetcher êµ¬í˜„
- [x] Task 6.3: MetadataEnricher ë¦¬íŒ©í„°ë§
- [x] Task 6.4: ë³´ì•ˆ ê²€ì¦ (API í‚¤ ë§ˆìŠ¤í‚¹)

**Week 2, Days 3-4: Transformer & Batch**
- [x] Task 7.1-7.2: MetadataTransformer êµ¬í˜„
- [x] Task 7.3-7.4: ìˆœí™˜ ì˜ì¡´ ì°¨ë‹¨, í…ŒìŠ¤íŠ¸
- [x] Task 8: BatchProcessor êµ¬í˜„

**ì²´í¬í¬ì¸íŠ¸**: ëª¨ë“  ëª¨ë“ˆ ë…ë¦½ í…ŒìŠ¤íŠ¸ í†µê³¼

---

### Phase 4: Facade & Validation (2-3ì¼)

**Week 2, Days 5-6**
- [x] Task 9.1-9.3: Facade API ë¦¬ë””ìì¸
- [x] Task 9.4-9.6: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ êµ¬í˜„

**Week 3, Day 1**
- [x] Task 10.1-10.2: í†µí•© í…ŒìŠ¤íŠ¸ 10+ ì‹œë‚˜ë¦¬ì˜¤
- [x] Task 10.3: ì»¤ë²„ë¦¬ì§€ ì¸¡ì •
- [x] Task 10.4: ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§

**Week 3, Day 2**
- [x] Task 10.5: ë¬¸ì„œ ë° CI ì—…ë°ì´íŠ¸
- [x] ìµœì¢… íšŒê·€ í…ŒìŠ¤íŠ¸
- [x] PR ìƒì„± ë° ë¦¬ë·°

**ì´ ì˜ˆìƒ ì‹œê°„**: 10-11ì¼

---

## ğŸ¯ í’ˆì§ˆ ê²Œì´íŠ¸ (Quality Gates)

### Gate 1: Phase 1 ì™„ë£Œ ì‹œ
- [ ] TitleScorer ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼ (10+ tests)
- [ ] ì„±ëŠ¥: ê¸°ì¡´ ëŒ€ë¹„ Â±5% ì´ë‚´
- [ ] mypy strict: 0 errors
- [ ] MatchEvidence êµ¬ì¡° ê²€ì¦

### Gate 2: Phase 2 ì™„ë£Œ ì‹œ
- [ ] 3ê°œ scorer í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ScoringEngine ê°€ì¤‘ì¹˜ ê³„ì‚° ì •í™•ë„ ê²€ì¦
- [ ] íšŒê·€ í…ŒìŠ¤íŠ¸: ê¸°ì¡´ ì ìˆ˜ì™€ ë™ì¼ì„± í™•ì¸

### Gate 3: Phase 3 ì™„ë£Œ ì‹œ
- [ ] Fetcher ë„¤íŠ¸ì›Œí¬ mock í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] Transformer 3ê°€ì§€ ê²½ë¡œ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] BatchProcessor asyncio í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ë³´ì•ˆ: API í‚¤ ë§ˆìŠ¤í‚¹ í™•ì¸

### Gate 4: Phase 4 ì™„ë£Œ ì‹œ (ìµœì¢…)
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ 10+ ì‹œë‚˜ë¦¬ì˜¤ í†µê³¼
- [ ] pytest --cov: 80%+ ì»¤ë²„ë¦¬ì§€
- [ ] API í˜¸í™˜ì„±: 100% (ê¸°ì¡´ tests í†µê³¼)
- [ ] ì„±ëŠ¥: â‰¤5% ì˜¤ë²„í—¤ë“œ
- [ ] ë¬¸ì„œ: ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ ì™„ì„±
- [ ] CI: ëª¨ë“  íŒŒì´í”„ë¼ì¸ í†µê³¼

---

## ğŸ“Š Evidence Log (Planning Phase 1)

| Source | Pointer | Summary | Implication |
|--------|---------|---------|-------------|
| Code | services/metadata_enricher.py:42-59 | EnrichedMetadata dataclass | ğŸŸ¡ Transformer ë¶„ë¦¬ |
| Code | services/metadata_enricher.py:162-194 | DI íŒ¨í„´ ì´ë¯¸ ì ìš© | âœ… í™•ì¥ ìš©ì´ |
| Code | services/metadata_enricher.py:196-410 | enrich_metadata (~200 lines) | ğŸ”´ Fetcher ë¶„ë¦¬ í•„ìš” |
| Code | services/metadata_enricher.py:425-587 | enrich_batch (~160 lines) | ğŸŸ¡ BatchProcessor ë¶„ë¦¬ |
| Code | services/metadata_enricher.py:696-843 | _calculate_match_score (~150 lines) | ğŸ”´ MatchScorer ë¶„ë¦¬ |
| Code | services/metadata_enricher.py:844-945 | _calculate_title_similarity (~100 lines) | ğŸ”´ MatchScorer ë¶„ë¦¬ |
| Pattern | gui/themes/theme_manager.py:33-50 | Facade + DI ì„±ê³µ íŒ¨í„´ | âœ… ì¬ì‚¬ìš© |
| Test | tests/test_metadata_constants.py | ìƒìˆ˜ í…ŒìŠ¤íŠ¸ë§Œ ì¡´ì¬ | ğŸ”´ í†µí•© í…ŒìŠ¤íŠ¸ ë¶€ì¡± |

---

## ğŸ² Tradeoff Analysis (Planning Phase 2)

| Option | Pros | Cons | Complexity | Preferred |
|--------|------|------|------------|-----------|
| **A: ìˆ˜í‰ ë¶„í• ** | Theme Manager íŒ¨í„´ ì¬ì‚¬ìš©, ê°„ë‹¨í•¨, ë¹ ë¥¸ êµ¬í˜„ | scorer.py ì—¬ì „íˆ í¼ (250 lines), í™•ì¥ì„± ì œí•œ | Low | âŒ |
| **B: ìˆ˜ì§ ë¶„í• ** (Strategy) | ë§¤ì¹­ ë¡œì§ í™•ì¥ ìš©ì´, ê·¼ê±° ì œê³µ êµ¬ì¡°í™”, ì‘ì€ ëª¨ë“ˆ (50-100 lines) | êµ¬ì¡° ë³µì¡, ì˜¤ë²„ì—”ì§€ë‹ˆì–´ë§ ìš°ë ¤ | Medium | âœ… |

**ê²°ì •**: ì˜µì…˜ B (ìˆ˜ì§ ë¶„í• )
- **íˆ¬í‘œ**: 5í‘œ (ì‚¬í† ë¯¸ë‚˜, ë¦¬ë‚˜, ë°•ìš°ì„, ìµœë¡œê±´, ë‹ˆì•„) vs 1í‘œ (ê¹€ì§€ìœ )
- **ê·¼ê±°**: í™•ì¥ì„±, ê·¼ê±° íˆ¬ëª…ì„±, í…ŒìŠ¤íŠ¸ ìš©ì´ì„±

---

## âš ï¸ Risks & Mitigations (Planning Phase 3)

| Risk | Mitigation | Owner | Priority |
|------|------------|-------|----------|
| API í˜¸í™˜ì„± ê¹¨ì§ | Facade íŒ¨í„´ìœ¼ë¡œ ê¸°ì¡´ API ë³´ì¡´ | ìœ¤ë„í˜„ | ğŸ”´ High |
| ì„±ëŠ¥ ì €í•˜ (í•¨ìˆ˜ í˜¸ì¶œ ì˜¤ë²„í—¤ë“œ) | í”„ë¡œíŒŒì¼ë§ í›„ ë³‘ëª© ìµœì í™” | ì‚¬í† ë¯¸ë‚˜ | ğŸŸ¡ Medium |
| ìˆœí™˜ ì°¸ì¡° | ë‹¨ë°©í–¥ ì˜ì¡´ì„± ê°•ì œ (models â† base â† scorers â† engine â† enricher) | ìœ¤ë„í˜„ | ğŸ”´ High |
| íšŒê·€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ | í†µí•© í…ŒìŠ¤íŠ¸ ë¨¼ì € ì‘ì„± (Task 1) | ìµœë¡œê±´ | ğŸ”´ High |
| Mock ë³µì¡ë„ | pytest fixture ì¬ì‚¬ìš© | ìµœë¡œê±´ | ğŸŸ¡ Medium |
| API í‚¤ ë…¸ì¶œ | ë¡œê¹… ì‹œìŠ¤í…œ ê²€ì¦ (Task 6 ì¶”ê°€) | ë‹ˆì•„ | ğŸŸ¡ Medium |

---

## âœ… Review ê²°ê³¼ (Phase 0-5)

### PRD-Task ë§¤ì¹­ë¥ : 100% (10/10)

| PRD ì„¹ì…˜ | Task ID | ë§¤ì¹­ ìƒíƒœ |
|----------|---------|-----------|
| Scoring Module (models + base + 3 scorers) | 1,2,3,4 | âœ… |
| Scoring Orchestration (ì¶”ê°€ë¨) | 5 | âœ… |
| TMDB Fetcher | 6 | âœ… |
| Transformer | 7 | âœ… |
| Batch Processor | 8 | âœ… |
| Facade | 9 | âœ… |
| Validation | 10 | âœ… |

### ëª…ë ¹ ëª…í™•ì„±: 100% (ì—…ë°ì´íŠ¸ í›„)

**ìˆ˜ì • ë‚´ì—­**:
- âœ… Task 1: ê²½ë¡œ êµ¬ì²´í™” (`src/anivault/services/metadata_enricher/scoring/`)
- âœ… Task 6: ë³´ì•ˆ ìš”êµ¬ì‚¬í•­ ì¶”ê°€ (API í‚¤ ë§ˆìŠ¤í‚¹)
- âœ… Task 7: í—¬í¼ í•¨ìˆ˜ 4ê°œ ëª…ì‹œ
- âœ… Task 8: BatchResult êµ¬ì¡° ëª…ì‹œ

### 8ì¸ í˜ë¥´ì†Œë‚˜ ìŠ¹ì¸: 8/8 âœ…

| í˜ë¥´ì†Œë‚˜ | ì´ˆê¸° ì˜ê²¬ | ì¡°ê±´ | ìˆ˜ì • í›„ | ìµœì¢… |
|---------|----------|------|---------|------|
| ìœ¤ë„í˜„/CLI | ì¡°ê±´ë¶€ | Task 1 ê²½ë¡œ | âœ… ì™„ë£Œ | âœ… |
| ì‚¬í† ë¯¸ë‚˜/Algo | ì ê·¹ ì°¬ì„± | - | - | âœ… |
| ê¹€ì§€ìœ /Data | ì°¬ì„± | - | - | âœ… |
| ë¦¬ë‚˜/UX | ì°¬ì„± | - | - | âœ… |
| ë°•ìš°ì„/Build | ì°¬ì„± | - | - | âœ… |
| ìµœë¡œê±´/QA | ì¡°ê±´ë¶€ | Task 7,8 êµ¬ì²´í™” | âœ… ì™„ë£Œ | âœ… |
| ë‹ˆì•„/Security | ì¡°ê±´ë¶€ | Task 6 ë³´ì•ˆ | âœ… ì™„ë£Œ | âœ… |
| ì •í•˜ë¦¼/License | ì°¬ì„± | - | - | âœ… |

---

## ğŸ¯ í•µì‹¬ ê°œì„ ì‚¬í•­

### 1. Match Evidence (íˆ¬ëª…ì„±)
**Before**:
```python
# ì ìˆ˜ë§Œ ë°˜í™˜, ê·¼ê±° ì—†ìŒ
best_match = {"id": 123, "title": "...", "score": 0.85}
```

**After**:
```python
# ì ìˆ˜ + ê·¼ê±° ì œê³µ
best_match = ScoreResult(
    total_score=0.85,
    evidences=[
        MatchEvidence(
            feature="title_similarity",
            score=0.9,
            reason="High similarity: Attack on Titan vs é€²æ’ƒã®å·¨äºº",
            weight=0.6
        ),
        MatchEvidence(
            feature="year_match",
            score=1.0,
            reason="Exact year match: 2013",
            weight=0.3
        ),
        MatchEvidence(
            feature="media_type",
            score=1.0,
            reason="Type match: tv",
            weight=0.1
        )
    ],
    raw_scores={"title": 0.9, "year": 1.0, "media_type": 1.0}
)
```

**ì‚¬ìš©ì ê²½í—˜**:
- GUI íˆ´íŒ: "ì œëª© ìœ ì‚¬ë„ 90%, ì—°ë„ ì •í™•íˆ ì¼ì¹˜, TV íƒ€ì… ì¼ì¹˜"
- CLI ì¶œë ¥: `--verbose` ëª¨ë“œì—ì„œ ê·¼ê±° í‘œì‹œ
- ë””ë²„ê¹…: ì™œ ì´ ì ìˆ˜ì¸ì§€ ì¦‰ì‹œ íŒŒì•…

---

### 2. Extensibility (í™•ì¥ì„±)
**Before**:
```python
# scorer ì¶”ê°€ ì‹œ _calculate_match_score ìˆ˜ì • í•„ìš”
def _calculate_match_score(self, file_info, candidate):
    score = title_similarity * 0.6
    score += year_bonus * 0.3
    score += media_type_bonus * 0.1
    # ìƒˆ scorer ì¶”ê°€í•˜ë ¤ë©´ ì—¬ê¸° ìˆ˜ì • âŒ
    return score
```

**After**:
```python
# ìƒˆ scorerëŠ” ê·¸ëƒ¥ ì¶”ê°€ë§Œ í•˜ë©´ ë¨
engine = ScoringEngine([
    TitleScorer(weight=0.6),
    YearScorer(weight=0.3),
    MediaTypeScorer(weight=0.1),
    GenreScorer(weight=0.2),      # NEW! ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • ë¶ˆí•„ìš” âœ…
    RuntimeScorer(weight=0.1),    # NEW!
])
```

---

### 3. Testability (í…ŒìŠ¤íŠ¸ ìš©ì´ì„±)
**Before**:
```python
# 874-line í´ë˜ìŠ¤ â†’ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë¶ˆê°€ëŠ¥
class TestMetadataEnricher:
    def test_enrich_metadata(self):
        # TMDB mock + ëª¨ë“  ë¡œì§ í†µí•© í…ŒìŠ¤íŠ¸ë§Œ ê°€ëŠ¥
        ...
```

**After**:
```python
# ê° scorer ë…ë¦½ í…ŒìŠ¤íŠ¸
class TestTitleScorer:
    def test_exact_match(self):
        scorer = TitleScorer(weight=1.0)
        result = scorer.score(
            ParsingResult(title="Attack on Titan"),
            {"title": "Attack on Titan"}
        )
        assert result.total_score == 1.0
        assert result.evidences[0].reason == "Exact title match"

    def test_unicode_similarity(self):
        # ìœ ë‹ˆì½”ë“œ íŠ¹ìˆ˜ ì¼€ì´ìŠ¤
        ...

    def test_empty_title(self):
        # ê²½ê³„ê°’ í…ŒìŠ¤íŠ¸
        ...
```

---

## ğŸ”’ Security Enhancements

### API í‚¤ ë§ˆìŠ¤í‚¹ (ë‹ˆì•„ ìš”ì²­)
**Task 6 ì¶”ê°€ ìš”êµ¬ì‚¬í•­**:
```python
# fetcher.pyì—ì„œ ë¡œê¹… ì‹œ
log_operation_error(
    logger=logger,
    operation="search_matches",
    error=error,
    additional_context={
        "title": file_info.title,
        # API í‚¤ëŠ” ìë™ ë§ˆìŠ¤í‚¹ë¨ (shared/logging.py)
    }
)
```

**ê²€ì¦**:
- [ ] `caplog`ë¡œ ë¡œê·¸ì— í‰ë¬¸ API í‚¤ ì—†ìŒ í™•ì¸
- [ ] URL íŒŒë¼ë¯¸í„°ì— ë¯¼ê° ì •ë³´ ì—†ìŒ í™•ì¸
- [ ] ErrorContextì— API í‚¤ ë¯¸í¬í•¨ í™•ì¸

---

## ğŸ“š ë¬¸ì„œ ì—…ë°ì´íŠ¸ ê³„íš

### 1. ì•„í‚¤í…ì²˜ ë¬¸ì„œ
**íŒŒì¼**: `docs/architecture/metadata-enricher.md`

**ë‚´ìš©**:
- ëª¨ë“ˆ ë‹¤ì´ì–´ê·¸ë¨ (before/after)
- ì˜ì¡´ì„± ê·¸ë˜í”„
- DI íŒ¨í„´ ì„¤ëª…
- ê° ëª¨ë“ˆ ì±…ì„

### 2. ê°œë°œ ê°€ì´ë“œ
**íŒŒì¼**: `docs/dev-guide/extending-scorers.md`

**ë‚´ìš©**:
```markdown
## Scorer ì¶”ê°€ ë°©ë²•

### 1. BaseScorer êµ¬í˜„
\`\`\`python
class GenreScorer:
    def supports(self, file_info, candidate) -> bool:
        return hasattr(file_info, 'genre') and 'genres' in candidate

    def score(self, file_info, candidate) -> ScoreResult:
        # ì¥ë¥´ ì˜¤ë²„ë© ê³„ì‚°
        overlap = len(set(file_info.genres) & set(candidate['genres']))
        score = overlap / len(set(file_info.genres) | set(candidate['genres']))

        evidence = MatchEvidence(
            feature="genre_overlap",
            score=score,
            reason=f"Common genres: {overlap}",
            weight=0.2
        )

        return ScoreResult(total_score=score * 0.2, evidences=[evidence])
\`\`\`

### 2. Engineì— ì¶”ê°€
\`\`\`python
engine = ScoringEngine([
    TitleScorer(weight=0.5),
    YearScorer(weight=0.2),
    MediaTypeScorer(weight=0.1),
    GenreScorer(weight=0.2),  # ì¶”ê°€!
])
\`\`\`

### 3. í…ŒìŠ¤íŠ¸ ì‘ì„±
\`\`\`python
# tests/services/scoring/test_genre_scorer.py
...
\`\`\`
```

### 3. README ì—…ë°ì´íŠ¸
**ì„¹ì…˜ ì¶”ê°€**: "Metadata Enrichment Architecture"
- DI ì‚¬ìš©ë²•
- ì»¤ìŠ¤í…€ scorer ì¶”ê°€ ì˜ˆì‹œ
- ì„±ëŠ¥ ìµœì í™” íŒ

---

## ğŸ§ª Test Strategy

### Unit Tests (ê° ëª¨ë“ˆë³„)
```
tests/services/
â”œâ”€â”€ scoring/
â”‚   â”œâ”€â”€ test_models.py           # ScoreResult, MatchEvidence ê²€ì¦
â”‚   â”œâ”€â”€ test_title_scorer.py     # ìœ ë‹ˆì½”ë“œ, ë¶€ë¶„ì¼ì¹˜, ê²½ê³„ê°’
â”‚   â”œâ”€â”€ test_year_scorer.py      # Â±1ë…„, None, ë²”ìœ„
â”‚   â”œâ”€â”€ test_media_type_scorer.py # TV/Movie, ë¶ˆì¼ì¹˜
â”‚   â””â”€â”€ test_engine.py           # ê°€ì¤‘ í•©ì‚°, supports í•„í„°ë§
â”œâ”€â”€ test_tmdb_fetcher.py         # API mock, ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜
â”œâ”€â”€ test_metadata_transformer.py # Pydantic/dict/None ê²½ë¡œ
â””â”€â”€ test_batch_processor.py      # asyncio, ì—ëŸ¬ ì§‘ê³„
```

**ì»¤ë²„ë¦¬ì§€ ëª©í‘œ**:
- models.py: 95%+
- scorers: 85%+
- fetcher/transformer/batch: 80%+
- enricher.py: 75%+ (í†µí•© í…ŒìŠ¤íŠ¸ë¡œ ì»¤ë²„)

### Integration Tests
```
tests/integration/
â””â”€â”€ test_enrichment_flow.py
    â”œâ”€â”€ test_full_enrichment_success
    â”œâ”€â”€ test_partial_enrichment
    â”œâ”€â”€ test_no_tmdb_results
    â”œâ”€â”€ test_low_confidence
    â”œâ”€â”€ test_network_error
    â”œâ”€â”€ test_api_rate_limit
    â”œâ”€â”€ test_batch_mixed_results
    â”œâ”€â”€ test_batch_all_failures
    â”œâ”€â”€ test_api_compatibility
    â””â”€â”€ test_match_evidence_structure
```

**httpx_mock ì‚¬ìš©**:
```python
@pytest.mark.asyncio
async def test_full_enrichment_success(httpx_mock):
    httpx_mock.add_response(
        url="https://api.themoviedb.org/3/search/multi",
        json={"results": [...]},
    )

    enricher = MetadataEnricher()
    result = await enricher.enrich_metadata(file_info)

    assert result.enrichment_status == "SUCCESS"
    assert len(result.match_evidence) > 0  # NEW!
```

---

## ğŸ“ˆ Performance Benchmarking

### Before/After ë¹„êµ ìŠ¤í¬ë¦½íŠ¸
```python
# scripts/benchmark_enricher.py
import asyncio
import time
from pathlib import Path

async def benchmark_enricher(enricher, test_files: list[ParsingResult]):
    start = time.perf_counter()
    results = await enricher.enrich_batch(test_files)
    duration = time.perf_counter() - start

    return {
        "duration": duration,
        "files_per_second": len(test_files) / duration,
        "avg_time_per_file": duration / len(test_files)
    }

# ì‹¤í–‰
before_stats = await benchmark_enricher(old_enricher, test_files)
after_stats = await benchmark_enricher(new_enricher, test_files)

overhead = (after_stats['duration'] - before_stats['duration']) / before_stats['duration'] * 100
assert overhead <= 5.0, f"Performance degradation: {overhead:.1f}%"
```

**ëª©í‘œ**:
- 100 íŒŒì¼ ì²˜ë¦¬ ì‹œê°„: â‰¤5% ì¦ê°€
- ë©”ëª¨ë¦¬ ì‚¬ìš©: â‰¤10% ì¦ê°€
- API í˜¸ì¶œ íšŸìˆ˜: ë™ì¼

---

## ğŸ“ Lessons Learned (Theme Manager ì°¸ì¡°)

### âœ… ì„±ê³µ íŒ¨í„´ ì¬ì‚¬ìš©

| íŒ¨í„´ | Theme Manager | MetadataEnricher |
|------|---------------|------------------|
| **Facade** | ThemeManager (236 lines) | MetadataEnricher (200 lines) |
| **DI** | validator, path_resolver, cache, loader | fetcher, scorers, transformer, batch |
| **ë‹¨ë°©í–¥ ì˜ì¡´** | Validator â† PathResolver â† Cache â† Loader â† Manager | models â† base â† scorers â† engine â† enricher |
| **per-file-ignores** | pyproject.toml í™œìš© | ë™ì¼ ì „ëµ |
| **ëª¨ë“ˆë³„ í…ŒìŠ¤íŠ¸** | test_theme_validator, test_theme_cache | test_title_scorer, test_engine |

### ğŸ“Š Theme Manager ì„±ê³¼ ì¬í˜„ ëª©í‘œ

| ì§€í‘œ | Theme Manager | MetadataEnricher ëª©í‘œ |
|------|---------------|----------------------|
| **ë¼ì¸ ê°ì†Œ** | 72% (842â†’236) | 65% (874â†’300) |
| **ëª¨ë“ˆ ìˆ˜** | 1â†’5 | 1â†’9 |
| **í…ŒìŠ¤íŠ¸ í†µê³¼** | 81 passed, 1 skipped | ê¸°ì¡´ + ì‹ ê·œ 80%+ |
| **íƒ€ì… ì»¤ë²„ë¦¬ì§€** | 100% | 100% |

---

## ğŸš€ Getting Started

### 1. í™˜ê²½ ì¤€ë¹„
```bash
# ë¸Œëœì¹˜ í™•ì¸
git branch --show-current
# â†’ feature/refactor-metadata-enricher âœ…

# Task Master íƒœê·¸ í™•ì¸
task-master tags
# â†’ feature-refactor-metadata-enricher (current) âœ…

# ë‹¤ìŒ íƒœìŠ¤í¬ í™•ì¸
task-master next
# â†’ Task 1: ìŠ¤ì½”ì–´ë§ ëª¨ë¸ ë° í”„ë¡œí† ì½œ ë¶„ë¦¬
```

### 2. Task 1 ì‹œì‘
```bash
# ìƒíƒœ ë³€ê²½
task-master set-status --id=1 --status=in-progress

# ìƒì„¸ ì •ë³´
task-master show 1

# ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p src/anivault/services/metadata_enricher/scoring
touch src/anivault/services/metadata_enricher/scoring/__init__.py
```

### 3. êµ¬í˜„ ìˆœì„œ
1. **models.py** ì‘ì„± (ScoreResult, MatchEvidence)
2. **base_scorer.py** ì‘ì„± (Protocol)
3. **pytest** ì‹¤í–‰í•˜ì—¬ import ê²€ì¦
4. **mypy** ì‹¤í–‰í•˜ì—¬ íƒ€ì… ê²€ì¦
5. Task 1 ì™„ë£Œ â†’ `set-status --id=1 --status=done`

---

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë¦¬íŒ©í† ë§ ì „
- [x] í˜„ì¬ ê¸°ëŠ¥ ë™ì‘ í™•ì¸ âœ…
- [x] ê¸°ì¡´ í…ŒìŠ¤íŠ¸ í™•ì¸ âœ… (test_metadata_constants.pyë§Œ ì¡´ì¬)
- [x] ì˜ì¡´ì„± ê·¸ë˜í”„ ì‘ì„± âœ…
- [x] Git ë¸Œëœì¹˜ ìƒì„± âœ…
- [x] Task Master íƒœê·¸ ìƒì„± âœ…
- [x] PRD ì‘ì„± âœ… (830 words)
- [x] 10 tasks, 28 subtasks ìƒì„± âœ…
- [x] ë³µì¡ë„ ë¶„ì„ ì™„ë£Œ âœ…
- [x] PRD-Task ë§¤ì¹­ ê²€ì¦ âœ…
- [x] ë³´ì•ˆ ìš”êµ¬ì‚¬í•­ ì¶”ê°€ âœ…

### ë¦¬íŒ©í† ë§ ì¤‘ (ê° Phase)
- [ ] í•œ ë²ˆì— í•˜ë‚˜ì˜ ëª¨ë“ˆë§Œ ì‘ì—…
- [ ] ê° ë‹¨ê³„ë§ˆë‹¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
- [ ] ì»¤ë°‹ ë©”ì‹œì§€ ëª…í™•íˆ ì‘ì„± (Conventional Commits)
- [ ] Task Master ì„œë¸ŒíƒœìŠ¤í¬ ìƒíƒœ ì—…ë°ì´íŠ¸
- [ ] API í˜¸í™˜ì„± ìœ ì§€ í™•ì¸

### ë¦¬íŒ©í† ë§ í›„
- [ ] ì „ì²´ í…ŒìŠ¤íŠ¸ í†µê³¼ (pytest)
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë¹„êµ (â‰¤5%)
- [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸ (ì•„í‚¤í…ì²˜, í™•ì¥ ê°€ì´ë“œ)
- [ ] ë¦´ë¦¬ì¦ˆ ë…¸íŠ¸ ì‘ì„±
- [ ] PR ìƒì„± ë° ë¦¬ë·°

---

## ğŸ¯ ì˜ˆìƒ ì»¤ë°‹ ì‹œí€€ìŠ¤ (Theme Manager ì°¸ì¡°)

### Phase 1: Scorer Extraction
```bash
# Commit 1
feat(services/scoring): Add ScoreResult and MatchEvidence models
- Create scoring/models.py with Pydantic dataclasses
- Define MatchEvidence structure for transparency
- Add ScoreResult for aggregated scoring

# Commit 2
feat(services/scoring): Add BaseScorer protocol
- Create scoring/base_scorer.py
- Define score() and supports() interface
- Enable Strategy pattern

# Commit 3
feat(services/scoring): Extract TitleScorer class
- Extract _calculate_title_similarity to title_scorer.py
- Add MatchEvidence generation
- Maintain existing algorithm

# Commit 4
test(services/scoring): Add TitleScorer unit tests
- Add test_title_scorer.py with 10+ scenarios
- Verify unicode handling
- Benchmark performance (Â±5%)
```

### Phase 2: Engine & Scorers
```bash
# Commit 5
feat(services/scoring): Add YearScorer and MediaTypeScorer
- Extract year bonus logic to year_scorer.py
- Extract media type logic to media_type_scorer.py
- Add unit tests for both

# Commit 6
feat(services/scoring): Add ScoringEngine orchestration
- Create scoring/engine.py
- Implement weighted score aggregation
- Replace _calculate_match_score with engine
```

### Phase 3: Fetcher/Transformer/Batch
```bash
# Commit 7
feat(services): Extract TMDBMetadataFetcher module
- Create fetcher.py with search/details methods
- Add API key masking verification
- Add TMDBClient mock tests

# Commit 8
feat(services): Extract MetadataTransformer module
- Create transformer.py with 4 helper functions
- Handle Pydantic/dict/None paths
- Add conversion tests

# Commit 9
feat(services): Extract BatchProcessor module
- Create batch_processor.py with BatchResult
- Implement asyncio error aggregation
- Add concurrent processing tests
```

### Phase 4: Facade & Final
```bash
# Commit 10
refactor(services): Transform MetadataEnricher to Facade (874â†’300 lines)
- Move to enricher.py
- Inject all dependencies
- Maintain API compatibility
- Add deprecation warnings to old path

# Commit 11
test(services): Add integration tests for enrichment flow
- Add 10+ end-to-end scenarios
- Verify Match Evidence in all results
- Achieve 80%+ coverage

# Commit 12
docs(services): Update architecture and guides
- Add module diagram
- Document DI usage
- Add scorer extension guide
- Update README

# Commit 13 (Optional)
perf(services): Optimize enricher performance
- Profile and fix bottlenecks
- Ensure â‰¤5% overhead
- Update benchmarks
```

**ì´ ì˜ˆìƒ**: 10-13 commits

---

## ğŸ¯ Success Metrics (ìµœì¢… ê²€ì¦)

### ì½”ë“œ ì§€í‘œ
| ì§€í‘œ | Before | After | ëª©í‘œ | ìƒíƒœ |
|------|--------|-------|------|------|
| **ì´ ë¼ì¸ ìˆ˜** | 874 | ~800 (ë¶„ì‚°) | -65% | â³ |
| **enricher.py** | 874 | ~300 | âœ… | â³ |
| **í‰ê·  íŒŒì¼ í¬ê¸°** | 874 | ~89 (9íŒŒì¼) | <200 | â³ |
| **í´ë˜ìŠ¤ë‹¹ ë©”ì„œë“œ** | 11 | 3-5 | <6 | â³ |

### í’ˆì§ˆ ì§€í‘œ
| ë„êµ¬ | ëª©í‘œ | ìƒíƒœ |
|------|------|------|
| **ruff** | 0 errors | â³ |
| **mypy strict** | 0 errors | â³ |
| **pytest** | 0 failures | â³ |
| **bandit** | 0 high | â³ |
| **coverage** | 80%+ | â³ |

### ì„±ëŠ¥ ì§€í‘œ
| í•­ëª© | Before | After | ëª©í‘œ | ìƒíƒœ |
|------|--------|-------|------|------|
| **100 íŒŒì¼ ì²˜ë¦¬** | Tì´ˆ | â‰¤T*1.05ì´ˆ | â‰¤5% | â³ |
| **ë©”ëª¨ë¦¬ ì‚¬ìš©** | M MB | â‰¤M*1.1 MB | â‰¤10% | â³ |
| **API í˜¸ì¶œ ìˆ˜** | N | N | ë™ì¼ | â³ |

---

## ğŸ­ 8ì¸ í˜ë¥´ì†Œë‚˜ ê´€ì 

### [ìœ¤ë„í˜„/CLI] - Python ë°±ì—”ë“œ ì „ë¬¸ê°€
**ê´€ì‹¬ì‚¬**:
- ëª¨ë“ˆ êµ¬ì¡° ëª…í™•ì„±
- import ê²½ë¡œ ì¼ê´€ì„±
- í…ŒìŠ¤íŠ¸ ìš©ì´ì„±

**ê¸°ì—¬**:
- ê²½ë¡œ êµ¬ì²´í™” ìš”ì²­ (Task 1)
- Facade íŒ¨í„´ ì„¤ê³„
- ë‹¨ê³„ì  êµ¬í˜„ ì „ëµ

---

### [ì‚¬í† ë¯¸ë‚˜/Algo] - ì•Œê³ ë¦¬ì¦˜ ì „ë¬¸ê°€
**ê´€ì‹¬ì‚¬**:
- ë§¤ì¹­ ì ìˆ˜ íˆ¬ëª…ì„±
- scorer í™•ì¥ì„±
- ì„±ëŠ¥ ìµœì í™”

**ê¸°ì—¬**:
- Strategy íŒ¨í„´ ì œì•ˆ (ì˜µì…˜ B)
- MatchEvidence êµ¬ì¡° ì„¤ê³„
- ScoringEngine í•„ìš”ì„± íŒŒì•…

**ëª…ì–¸**: *"ê°€ì •ì€ ì ìˆ˜ë¡œ ë§í•˜ë¼. í›„ë³´ëŠ” ìˆ¨ê¸°ì§€ ë§ê³  ê·¼ê±°ë¥¼ ë…¸ì¶œ."*

---

### [ê¹€ì§€ìœ /Data] - ë°ì´í„° í’ˆì§ˆ ì „ë¬¸ê°€
**ê´€ì‹¬ì‚¬**:
- ë°ì´í„° íë¦„ ëª…í™•ì„±
- ì—ëŸ¬ ì§‘ê³„ êµ¬ì¡°
- ì˜ì¡´ì„± ê·¸ë˜í”„

**ê¸°ì—¬**:
- BatchResult êµ¬ì¡° ëª…ì‹œ ìš”ì²­
- ì˜ì¡´ì„± ê²€ì¦ (ìˆœí™˜ ì°¸ì¡° ì—†ìŒ í™•ì¸)
- ë°ì´í„° ë³€í™˜ ë¡œì§ ë¶„ë¦¬ ì œì•ˆ

---

### [ë¦¬ë‚˜/UX] - GUI/UX ì „ë¬¸ê°€
**ê´€ì‹¬ì‚¬**:
- Match Evidence í™œìš©
- ì‚¬ìš©ì íˆ¬ëª…ì„±
- ë¬¸ì„œ ì™„ì„±ë„

**ê¸°ì—¬**:
- MatchEvidenceì˜ UX ê°€ì¹˜ ê°•ì¡°
- í—¬í¼ í•¨ìˆ˜ êµ¬ì²´í™” ìš”ì²­ (Task 7)
- ë¬¸ì„œí™” ê³„íš ê²€ì¦

**ëª…ì–¸**: *"ì‚¬ìš©ìëŠ” 'ì™œ ì´ ë§¤ì¹­?'ì„ ì•Œê³  ì‹¶ì–´í•´."*

---

### [ë°•ìš°ì„/Build] - Windows íŒ¨í‚¤ì§• ì „ë¬¸ê°€
**ê´€ì‹¬ì‚¬**:
- ë¹Œë“œ ì‹œê°„
- ëª¨ë“ˆ ë¶„ë¦¬ ì˜í–¥
- CI/CD íŒŒì´í”„ë¼ì¸

**ê¸°ì—¬**:
- ì¦ë¶„ ë¹Œë“œ ì´ì  í™•ì¸
- CI ì—…ë°ì´íŠ¸ ê³„íš ê²€í† 

---

### [ìµœë¡œê±´/QA] - í…ŒìŠ¤íŠ¸/QA ì „ë¬¸ê°€
**ê´€ì‹¬ì‚¬**:
- í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€
- íšŒê·€ ë°©ì§€
- ëª…ë ¹ ëª…í™•ì„±

**ê¸°ì—¬**:
- ë³µì¡ë„ 7+ íƒœìŠ¤í¬ í™•ì¥ ì œì•ˆ
- ëª¨í˜¸ì„± 14% â†’ 0% ê°œì„  ì£¼ë„
- í†µí•© í…ŒìŠ¤íŠ¸ 10+ ì‹œë‚˜ë¦¬ì˜¤ ì œì•ˆ

**ëª…ì–¸**: *"ì‘ì€ ëª¨ë“ˆì€ í…ŒìŠ¤íŠ¸í•˜ê¸° ì‰¬ì›Œ."*

---

### [ë‹ˆì•„/Security] - ë³´ì•ˆ ì „ë¬¸ê°€
**ê´€ì‹¬ì‚¬**:
- API í‚¤ ë…¸ì¶œ ë°©ì§€
- ë¡œê¹… ë³´ì•ˆ
- ì…ë ¥ ê²€ì¦

**ê¸°ì—¬**:
- Task 6ì— API í‚¤ ë§ˆìŠ¤í‚¹ ìš”êµ¬ì‚¬í•­ ì¶”ê°€ (MUST)
- ë³´ì•ˆ ê°ì‚¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì œê³µ
- ë¯¼ê° ì •ë³´ ë¡œê¹… ê²€ì¦

**ëª…ì–¸**: *"í° íŒŒì¼ì€ ë³´ì•ˆ ë¦¬ë·°ê°€ ì–´ë ¤ì›Œ. ì±…ì„ë³„ë¡œ ë¶„ë¦¬í•˜ë©´ ë¦¬ë·°ê°€ ì‰¬ì›Œì ¸."*

---

### [ì •í•˜ë¦¼/License] - ë¼ì´ì„ ìŠ¤ ì „ë¬¸ê°€
**ê´€ì‹¬ì‚¬**:
- ì˜ì¡´ì„± ë³€ê²½
- ë¼ì´ì„ ìŠ¤ í˜¸í™˜ì„±

**ê¸°ì—¬**:
- ì˜ì¡´ì„± ë³€ê²½ ì—†ìŒ í™•ì¸
- ì»´í”Œë¼ì´ì–¸ìŠ¤ ë¬¸ì œì—†ìŒ ìŠ¹ì¸

---

## ğŸ”— ì°¸ê³  ë¬¸ì„œ

### í”„ë¡œí† ì½œ
- [PLANNING_PROTOCOL.md](../protocols/PLANNING_PROTOCOL.md) - ê¸°íš í”„ë¡œí† ì½œ
- [TASKMASTER_WORKFLOW_PROTOCOL.md](../protocols/TASKMASTER_WORKFLOW_PROTOCOL.md) - Task Master ì›Œí¬í”Œë¡œìš°
- [REVIEW_PROTOCOL.md](../protocols/REVIEW_PROTOCOL.md) - ê²€í†  í”„ë¡œí† ì½œ
- [DEVELOPMENT_PROTOCOL.md](../protocols/DEVELOPMENT_PROTOCOL.md) - ê°œë°œ í”„ë¡œí† ì½œ

### ê·œì¹™
- [02_python_development.mdc](../../.cursor/rules/02_python_development.mdc) - Python ê°œë°œ í‘œì¤€
- [04_quality_assurance.mdc](../../.cursor/rules/04_quality_assurance.mdc) - í’ˆì§ˆ ë³´ì¦
- [one_source_of_truth.mdc](../../.cursor/rules/one_source_of_truth.mdc) - ì¤‘ë³µ ë°©ì§€

### ì°¸ì¡° êµ¬í˜„
- [theme_manager.py](../../src/anivault/gui/themes/theme_manager.py) - Facade ì„±ê³µ ì‚¬ë¡€
- [refactoring-briefing.md](../refactoring-briefing.md) - ì „ì²´ ë¦¬íŒ©í† ë§ í˜„í™©

### Task Master
- PRD: `.taskmaster/docs/feature-refactor-metadata-enricher-prd.txt`
- Tasks: `.taskmaster/tasks/tasks.json` (tag: feature-refactor-metadata-enricher)
- Complexity Report: `.taskmaster/reports/task-complexity-report_feature-refactor-metadata-enricher.json`

---

## ğŸ¬ ë‹¤ìŒ ë‹¨ê³„

### ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥
```bash
# 1. ë‹¤ìŒ íƒœìŠ¤í¬ í™•ì¸
task-master next

# 2. Task 1 ì‹œì‘
task-master set-status --id=1 --status=in-progress

# 3. ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p src/anivault/services/metadata_enricher/scoring
mkdir -p tests/services/scoring

# 4. models.py ì‘ì„± ì‹œì‘
code src/anivault/services/metadata_enricher/scoring/models.py
```

### ë°˜ë³µ íŒ¨í„´ (ê° íƒœìŠ¤í¬ë§ˆë‹¤)
1. **ê³„íš**: `task-master show <id>` - íƒœìŠ¤í¬ ìƒì„¸ í™•ì¸
2. **íƒìƒ‰**: ê¸°ì¡´ ì½”ë“œ ë¶„ì„, ì¦ê±° ìˆ˜ì§‘
3. **êµ¬í˜„**: ëª¨ë“ˆ ì‘ì„±
4. **í…ŒìŠ¤íŠ¸**: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± ë° ì‹¤í–‰
5. **ê²€ì¦**: ruff/mypy/pytest í†µê³¼
6. **ì—…ë°ì´íŠ¸**: `task-master update-subtask --id=<id> --prompt="..."`
7. **ì™„ë£Œ**: `task-master set-status --id=<id> --status=done`
8. **ì»¤ë°‹**: Conventional Commits í˜•ì‹

---

## ğŸ“Š í”„ë¡œí† ì½œ ì¤€ìˆ˜ í˜„í™©

| í”„ë¡œí† ì½œ | Phase | ì™„ë£Œ | ì‚°ì¶œë¬¼ |
|---------|-------|------|--------|
| **PLANNING** | 0-5 | âœ… | PRD-lite, Evidence, Tradeoff, Risks, WBS, Consensus |
| **TASKMASTER** | 0-6 | âœ… | Tag, PRD, 10 tasks, 28 subtasks, Complexity, Validation |
| **REVIEW** | 0-5 | âœ… | Change Summary, Quality, Security, UX, Approval Matrix |
| **DEVELOPMENT** | 0-4 | â³ | êµ¬í˜„ ì˜ˆì • |

**í’ˆì§ˆ ê²Œì´íŠ¸**: ëª¨ë‘ í†µê³¼ âœ…

---

## ğŸ‰ ìµœì¢… ìƒíƒœ

### âœ… ì™„ë£Œëœ ì‘ì—…
- [x] Git ë¸Œëœì¹˜ ìƒì„±
- [x] Task Master íƒœê·¸ ìƒì„±
- [x] PRD ì‘ì„± (830 words)
- [x] 10 tasks íŒŒì‹±
- [x] ë³µì¡ë„ ë¶„ì„ (5 tasks í™•ì¥)
- [x] 27 subtasks ìƒì„±
- [x] ì˜ì¡´ì„± ê²€ì¦
- [x] PRD-Task 100% ë§¤ì¹­
- [x] ëª¨í˜¸ì„± ì œê±° (86%â†’100%)
- [x] ë³´ì•ˆ ìš”êµ¬ì‚¬í•­ ì¶”ê°€
- [x] 8ì¸ í˜ë¥´ì†Œë‚˜ ë§Œì¥ì¼ì¹˜ ìŠ¹ì¸

### â³ ë‹¤ìŒ ì‘ì—…
- [ ] Task 1 êµ¬í˜„ ì‹œì‘
- [ ] Phase 1 ì™„ë£Œ (3-4ì¼)
- [ ] Phase 2 ì™„ë£Œ (2ì¼)
- [ ] Phase 3 ì™„ë£Œ (3-4ì¼)
- [ ] Phase 4 ì™„ë£Œ (2-3ì¼)
- [ ] PR ìƒì„± ë° ë¦¬ë·°

---

**ìƒíƒœ**: ğŸš€ **êµ¬í˜„ ì¤€ë¹„ ì™„ë£Œ**
**ë‹¤ìŒ**: `task-master next` ì‹¤í–‰í•˜ì—¬ Task 1 ì‹œì‘
**ì˜ˆìƒ ì™„ë£Œ**: 2025-10-22 ~ 2025-10-25 (10-11ì¼)

---

**Version**: 1.0
**Last Updated**: 2025-10-12
**Contributors**: 8-Persona Planning Team
**Status**: âœ… Planning Complete, Ready for Implementation
