#!/usr/bin/env python3
"""
í†µí•© ì½”ë“œ í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ

ì•ì„œ ê°œë°œí•œ ì„¸ ê°œì˜ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•©í•˜ì—¬ ì¢…í•©ì ì¸ ì½”ë“œ í’ˆì§ˆ ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
- ë§¤ì§ ê°’ íƒì§€ (validate_magic_values.py)
- í•¨ìˆ˜ ê¸¸ì´ ë° ë³µì¡ë„ ê²€ì¦ (validate_function_length.py)
- ì—ëŸ¬ ì²˜ë¦¬ íŒ¨í„´ ê²€ì¦ (validate_error_handling.py)
"""

from __future__ import annotations

import argparse
import json
import subprocess  # nosec B404 - Safe usage in validation scripts
import sys
from datetime import datetime
from pathlib import Path
from typing import Any


class CodeQualityValidator:
    """í†µí•© ì½”ë“œ í’ˆì§ˆ ê²€ì¦ê¸°"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.scripts_dir = self.project_root / "scripts"

        # ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œë“¤
        self.magic_values_script = self.scripts_dir / "validate_magic_values.py"
        self.function_length_script = self.scripts_dir / "validate_function_length.py"
        self.error_handling_script = self.scripts_dir / "validate_error_handling.py"

        # ê²°ê³¼ ì €ì¥
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "project_root": str(self.project_root),
            "validations": {
                "magic_values": {"violations": [], "status": "pending"},
                "function_length": {"violations": [], "status": "pending"},
                "error_handling": {"violations": [], "status": "pending"},
            },
            "summary": {
                "total_files_analyzed": 0,
                "total_violations": 0,
                "violations_by_type": {},
                "violations_by_severity": {},
                "overall_status": "pending",
            },
        }

    def run_validation(
        self,
        paths: list[str],
        exclude_patterns: list[str] | None = None,
    ) -> dict[str, Any]:
        """í†µí•© ê²€ì¦ ì‹¤í–‰"""
        if exclude_patterns is None:
            exclude_patterns = []

        print("ğŸ” Starting comprehensive code quality validation...")
        print(f"ğŸ“ Project root: {self.project_root}")
        print(f"ğŸ“‚ Analyzing paths: {', '.join(paths)}")
        if exclude_patterns:
            print(f"ğŸš« Excluding patterns: {', '.join(exclude_patterns)}")
        print()

        # 1. ë§¤ì§ ê°’ ê²€ì¦
        print("1ï¸âƒ£ Validating magic values...")
        self._run_magic_values_validation(paths, exclude_patterns)

        # 2. í•¨ìˆ˜ ê¸¸ì´ ë° ë³µì¡ë„ ê²€ì¦
        print("2ï¸âƒ£ Validating function length and complexity...")
        self._run_function_length_validation(paths, exclude_patterns)

        # 3. ì—ëŸ¬ ì²˜ë¦¬ íŒ¨í„´ ê²€ì¦
        print("3ï¸âƒ£ Validating error handling patterns...")
        self._run_error_handling_validation(paths, exclude_patterns)

        # 4. ê²°ê³¼ ë¶„ì„ ë° ìš”ì•½
        print("4ï¸âƒ£ Analyzing results and generating summary...")
        self._analyze_results()

        return self.results

    def _run_magic_values_validation(
        self,
        paths: list[str],
        exclude_patterns: list[str],  # noqa: ARG002
    ) -> None:
        """ë§¤ì§ ê°’ ê²€ì¦ ì‹¤í–‰"""
        try:
            cmd = [sys.executable, str(self.magic_values_script), *paths]
            result = subprocess.run(  # nosec B603 - Trusted internal validation script
                cmd,
                capture_output=True,
                text=True,
                encoding="utf-8",
                errors="replace",
                cwd=self.project_root,
                check=False,
            )

            if result.returncode == 0:
                self.results["validations"]["magic_values"]["status"] = "passed"
                print("   âœ… No magic values found")
            else:
                self.results["validations"]["magic_values"]["status"] = "failed"
                self.results["validations"]["magic_values"]["output"] = result.stdout
                self.results["validations"]["magic_values"]["error"] = result.stderr
                print("   âŒ Magic values found")
                print(f"   ğŸ“ Output: {result.stdout.strip()}")
        except (OSError, subprocess.SubprocessError) as e:
            self.results["validations"]["magic_values"]["status"] = "error"
            self.results["validations"]["magic_values"]["error"] = str(e)
            print(f"   âš ï¸ Error running magic values validation: {e}")

    def _run_function_length_validation(
        self,
        paths: list[str],
        exclude_patterns: list[str],
    ) -> None:
        """í•¨ìˆ˜ ê¸¸ì´ ë° ë³µì¡ë„ ê²€ì¦ ì‹¤í–‰"""
        try:
            cmd = [sys.executable, str(self.function_length_script), *paths]
            if exclude_patterns:
                cmd.extend(["--exclude", *exclude_patterns])
            result = subprocess.run(  # nosec B603 - Trusted internal validation script
                cmd,
                capture_output=True,
                text=True,
                encoding="utf-8",
                errors="replace",
                cwd=self.project_root,
                check=False,
            )

            if result.returncode == 0:
                self.results["validations"]["function_length"]["status"] = "passed"
                print("   âœ… No function length/complexity violations found")
            else:
                self.results["validations"]["function_length"]["status"] = "failed"
                self.results["validations"]["function_length"]["output"] = result.stdout
                self.results["validations"]["function_length"]["error"] = result.stderr
                print("   âŒ Function length/complexity violations found")
                print(f"   ğŸ“ Output: {result.stdout.strip()}")
        except (OSError, subprocess.SubprocessError) as e:
            self.results["validations"]["function_length"]["status"] = "error"
            self.results["validations"]["function_length"]["error"] = str(e)
            print(f"   âš ï¸ Error running function length validation: {e}")

    def _run_error_handling_validation(
        self,
        paths: list[str],
        exclude_patterns: list[str],
    ) -> None:
        """ì—ëŸ¬ ì²˜ë¦¬ íŒ¨í„´ ê²€ì¦ ì‹¤í–‰"""
        try:
            cmd = [sys.executable, str(self.error_handling_script), *paths]
            if exclude_patterns:
                cmd.extend(["--exclude", *exclude_patterns])
            result = subprocess.run(  # nosec B603 - Trusted internal validation script
                cmd,
                capture_output=True,
                text=True,
                encoding="utf-8",
                errors="replace",
                cwd=self.project_root,
                check=False,
            )

            if result.returncode == 0:
                self.results["validations"]["error_handling"]["status"] = "passed"
                print("   âœ… No error handling violations found")
            else:
                self.results["validations"]["error_handling"]["status"] = "failed"
                self.results["validations"]["error_handling"]["output"] = result.stdout
                self.results["validations"]["error_handling"]["error"] = result.stderr
                print("   âŒ Error handling violations found")
                print(f"   ğŸ“ Output: {result.stdout.strip()}")
        except (OSError, subprocess.SubprocessError) as e:
            self.results["validations"]["error_handling"]["status"] = "error"
            self.results["validations"]["error_handling"]["error"] = str(e)
            print(f"   âš ï¸ Error running error handling validation: {e}")

    def _analyze_results(self) -> None:
        """ê²°ê³¼ ë¶„ì„ ë° ìš”ì•½ ìƒì„±"""
        # ì „ì²´ ìƒíƒœ ê²°ì •
        all_passed = all(
            validation["status"] == "passed"
            for validation in self.results["validations"].values()
        )

        any_errors = any(
            validation["status"] == "error"
            for validation in self.results["validations"].values()
        )

        if any_errors:
            self.results["summary"]["overall_status"] = "error"
        elif all_passed:
            self.results["summary"]["overall_status"] = "passed"
        else:
            self.results["summary"]["overall_status"] = "failed"

        # ìœ„ë°˜ ì‚¬í•­ í†µê³„
        total_violations = 0
        violations_by_type = {}

        for validation_name, validation in self.results["validations"].items():
            if validation["status"] == "failed":
                # ì¶œë ¥ì—ì„œ ìœ„ë°˜ ì‚¬í•­ ìˆ˜ íŒŒì‹± (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
                output = validation.get("output", "")
                if "Found" in output and "violation" in output:
                    try:
                        # "Found X violation(s):" íŒ¨í„´ì—ì„œ ìˆ«ì ì¶”ì¶œ
                        import re

                        match = re.search(r"Found (\d+) violation", output)
                        if match:
                            count = int(match.group(1))
                            total_violations += count
                            violations_by_type[validation_name] = count
                    except (ValueError, AttributeError):
                        pass

        self.results["summary"]["total_violations"] = total_violations
        self.results["summary"]["violations_by_type"] = violations_by_type

        # íŒŒì¼ ìˆ˜ ê³„ì‚° (ëŒ€ëµì )
        analyzed_files = 0
        for validation in self.results["validations"].values():
            if "output" in validation and "Analyzed" in validation["output"]:
                try:
                    import re

                    match = re.search(r"Analyzed (\d+) files", validation["output"])
                    if match:
                        analyzed_files = max(analyzed_files, int(match.group(1)))
                except (ValueError, AttributeError):
                    pass

        self.results["summary"]["total_files_analyzed"] = analyzed_files

    def generate_report(
        self,
        output_format: str = "text",
        output_file: str | None = None,
    ) -> str:
        """ê²€ì¦ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        if output_format == "json":
            report = json.dumps(self.results, indent=2, ensure_ascii=False)
        else:
            report = self._generate_text_report()

        if output_file:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(report)
            print(f"ğŸ“„ Report saved to: {output_path}")

        return report

    def _generate_text_report(self) -> str:
        """í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        lines = []
        lines.append("=" * 80)
        lines.append("ğŸ” CODE QUALITY VALIDATION REPORT")
        lines.append("=" * 80)
        lines.append(f"ğŸ“… Timestamp: {self.results['timestamp']}")
        lines.append(f"ğŸ“ Project: {self.results['project_root']}")
        lines.append(
            f"ğŸ“Š Overall Status: {self.results['summary']['overall_status'].upper()}",
        )
        lines.append("")

        # ìš”ì•½ ì •ë³´
        lines.append("ğŸ“ˆ SUMMARY")
        lines.append("-" * 40)
        lines.append(
            f"Files Analyzed: {self.results['summary']['total_files_analyzed']}",
        )
        lines.append(f"Total Violations: {self.results['summary']['total_violations']}")
        lines.append("")

        # ê° ê²€ì¦ ê²°ê³¼
        lines.append("ğŸ” VALIDATION RESULTS")
        lines.append("-" * 40)

        for validation_name, validation in self.results["validations"].items():
            status_emoji = {
                "passed": "âœ…",
                "failed": "âŒ",
                "error": "âš ï¸",
                "pending": "â³",
            }.get(validation["status"], "â“")

            lines.append(
                f"{status_emoji} {validation_name.replace('_', ' ').title()}: {validation['status'].upper()}",
            )

            if validation["status"] == "failed" and "output" in validation:
                # ì£¼ìš” ìœ„ë°˜ ì‚¬í•­ë§Œ í‘œì‹œ
                output_lines = validation["output"].split("\n")
                for line in output_lines[:10]:  # ì²˜ìŒ 10ì¤„ë§Œ
                    if line.strip():
                        lines.append(f"    {line}")
                if len(output_lines) > 10:
                    lines.append(f"    ... and {len(output_lines) - 10} more lines")
                lines.append("")

            elif validation["status"] == "error" and "error" in validation:
                lines.append(f"    Error: {validation['error']}")
                lines.append("")

        # ê¶Œì¥ì‚¬í•­
        lines.append("ğŸ’¡ RECOMMENDATIONS")
        lines.append("-" * 40)

        if self.results["summary"]["overall_status"] == "passed":
            lines.append("ğŸ‰ Congratulations! All code quality checks passed.")
            lines.append("   Your code follows best practices for:")
            lines.append("   â€¢ Magic value elimination")
            lines.append("   â€¢ Function length and complexity")
            lines.append("   â€¢ Error handling patterns")
        else:
            lines.append("ğŸ”§ Code quality improvements needed:")

            for validation_name, validation in self.results["validations"].items():
                if validation["status"] == "failed":
                    if validation_name == "magic_values":
                        lines.append(
                            "   â€¢ Replace hardcoded strings/numbers with constants",
                        )
                    elif validation_name == "function_length":
                        lines.append(
                            "   â€¢ Break down long functions into smaller units",
                        )
                        lines.append("   â€¢ Reduce function complexity")
                    elif validation_name == "error_handling":
                        lines.append("   â€¢ Improve error handling patterns")
                        lines.append("   â€¢ Use structured logging instead of print")
                        lines.append(
                            "   â€¢ Add proper error context and user-friendly messages",
                        )

        lines.append("")
        lines.append("=" * 80)

        return "\n".join(lines)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="Comprehensive code quality validation system",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python scripts/validate_code_quality.py src/
  python scripts/validate_code_quality.py --exclude tests/ src/
  python scripts/validate_code_quality.py --format json --output report.json src/
  python scripts/validate_code_quality.py --format text --output report.txt src/
        """,
    )

    parser.add_argument("paths", nargs="+", help="File or directory paths to analyze")

    parser.add_argument(
        "--exclude",
        nargs="*",
        default=[],
        help="Patterns to exclude from analysis",
    )

    parser.add_argument(
        "--format",
        choices=["text", "json"],
        default="text",
        help="Output format (default: text)",
    )

    parser.add_argument("--output", help="Output file path (optional)")

    parser.add_argument(
        "--project-root",
        default=".",
        help="Project root directory (default: current directory)",
    )

    parser.add_argument("--verbose", action="store_true", help="Enable verbose output")

    args = parser.parse_args()

    # ê²€ì¦ê¸° ì´ˆê¸°í™”
    validator = CodeQualityValidator(args.project_root)

    # ê²€ì¦ ì‹¤í–‰
    results = validator.run_validation(args.paths, args.exclude)

    # ë¦¬í¬íŠ¸ ìƒì„±
    report = validator.generate_report(args.format, args.output)

    # ì¶œë ¥
    if not args.output:
        print("\n" + "=" * 80)
        print("ğŸ“„ VALIDATION REPORT")
        print("=" * 80)
        print(report)

    # ì¢…ë£Œ ì½”ë“œ ê²°ì •
    if results["summary"]["overall_status"] == "passed":
        return 0
    if results["summary"]["overall_status"] == "error":
        return 2
    return 1


if __name__ == "__main__":
    sys.exit(main())
