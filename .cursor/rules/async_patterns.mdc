---
description: Python asyncio asynchronous processing patterns and best practices guide
globs: src/core/*async*.py, src/core/*concurrent*.py, src/core/*parallel*.py, **/*async*.py
alwaysApply: false
---

# Python 비동기 처리 패턴 가이드

## 핵심 원칙

- **비동기 우선**: I/O 바운드 작업은 항상 비동기로 처리
- **동시성 제어**: Semaphore를 통한 동시 실행 수 제한
- **예외 격리**: 개별 작업 실패가 전체에 영향주지 않도록 처리
- **진행률 추적**: 실시간 진행 상황 콜백 제공

## 비동기 함수 설계

### **기본 비동기 함수 구조**
```python
# ✅ DO: 표준 비동기 함수 구조
async def process_files_async(
    files: list[AnimeFile], 
    progress_callback: Callable[[int, int], None] | None = None
) -> list[ProcessedFile]:
    """비동기 파일 처리 함수.
    
    Args:
        files: 처리할 파일 목록
        progress_callback: 진행률 콜백 함수
        
    Returns:
        처리된 파일 목록
    """
    results = []
    total_files = len(files)
    
    # 동시 실행 수 제한
    semaphore = asyncio.Semaphore(10)
    
    async def process_single_file(file: AnimeFile) -> ProcessedFile:
        async with semaphore:
            try:
                result = await _process_file_internal(file)
                return result
            except Exception as e:
                logger.warning(f"Failed to process {file.path}: {e}")
                return ProcessedFile(file=file, error=str(e))
    
    # 모든 파일을 동시에 처리
    tasks = [process_single_file(file) for file in files]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # 진행률 업데이트
    if progress_callback:
        progress_callback(len(results), total_files)
    
    return results
```

### **동시성 제어 패턴**
```python
# ✅ DO: Semaphore를 통한 동시 실행 제한
class ConcurrentProcessor:
    def __init__(self, max_concurrent: int = 10):
        self._semaphore = asyncio.Semaphore(max_concurrent)
    
    async def process_with_limit(self, items: list[Any]) -> list[Any]:
        async def process_item(item: Any) -> Any:
            async with self._semaphore:
                return await self._process_single_item(item)
        
        tasks = [process_item(item) for item in items]
        return await asyncio.gather(*tasks, return_exceptions=True)
```

## 비동기 컨텍스트 관리

### **비동기 컨텍스트 매니저**
```python
# ✅ DO: 비동기 리소스 관리
@asynccontextmanager
async def async_tmdb_client_context(api_key: str):
    """TMDB 클라이언트 비동기 컨텍스트 매니저."""
    client = None
    try:
        client = AsyncTMDBClient(api_key)
        await client.initialize()
        yield client
    finally:
        if client:
            await client.close()
```

### **스트리밍 처리 패턴**
```python
# ✅ DO: 결과를 실시간으로 처리
async def process_with_streaming(
    items: list[Any], 
    callback: Callable[[Any], None] | None = None
) -> list[Any]:
    """스트리밍 방식으로 아이템 처리."""
    results = []
    
    for coro in asyncio.as_completed(tasks):
        try:
            result = await coro
            results.append(result)
            
            if callback:
                callback(result)
        except Exception as e:
            logger.warning(f"Processing failed: {e}")
            if callback:
                callback(None, e)
    
    return results
```

## 에러 처리 및 복구

### **개별 작업 에러 격리**
```python
# ✅ DO: 개별 실패가 전체에 영향주지 않도록 처리
async def robust_batch_processing(items: list[Any]) -> BatchResult:
    """견고한 배치 처리."""
    tasks = [process_item(item) for item in items]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    successful = []
    failed = []
    
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            failed.append((items[i], result))
            logger.warning(f"Item {i} failed: {result}")
        else:
            successful.append(result)
    
    return BatchResult(
        successful=successful,
        failed=failed,
        success_rate=len(successful) / len(items)
    )
```

### **재시도 로직**
```python
# ✅ DO: 비동기 재시도 패턴
async def retry_async_operation(
    operation: Callable[[], Awaitable[T]],
    max_retries: int = 3,
    delay: float = 1.0
) -> T:
    """비동기 작업 재시도."""
    for attempt in range(max_retries + 1):
        try:
            return await operation()
        except Exception as e:
            if attempt == max_retries:
                raise
            
            wait_time = delay * (2 ** attempt)  # 지수 백오프
            logger.warning(f"Attempt {attempt + 1} failed: {e}, retrying in {wait_time}s")
            await asyncio.sleep(wait_time)
```

## 성능 최적화

### **배치 처리 최적화**
```python
# ✅ DO: 효율적인 배치 처리
class AsyncBatchProcessor:
    def __init__(self, batch_size: int = 100, max_concurrent: int = 10):
        self.batch_size = batch_size
        self.semaphore = asyncio.Semaphore(max_concurrent)
    
    async def process_large_dataset(self, items: list[Any]) -> list[Any]:
        """대용량 데이터셋 처리."""
        all_results = []
        
        for i in range(0, len(items), self.batch_size):
            batch = items[i:i + self.batch_size]
            
            async with self.semaphore:
                batch_results = await self._process_batch(batch)
                all_results.extend(batch_results)
        
        return all_results
```

### **메모리 효율적 처리**
```python
# ✅ DO: 메모리 효율적인 스트리밍 처리
async def process_large_file_stream(
    file_path: Path,
    chunk_size: int = 8192
) -> AsyncGenerator[bytes, None]:
    """대용량 파일을 청크 단위로 스트리밍 처리."""
    async with aiofiles.open(file_path, 'rb') as file:
        while chunk := await file.read(chunk_size):
            yield chunk
```

## 안티패턴 및 금지사항

### **❌ DON'T: 잘못된 비동기 패턴**
```python
# ❌ DON'T: 동기 함수를 비동기로 래핑
async def bad_async_wrapper():
    # 동기 함수를 비동기로 래핑하면 의미 없음
    return requests.get("https://api.example.com")

# ❌ DON'T: 블로킹 작업을 비동기 함수에서 직접 호출
async def bad_blocking_call():
    # 이렇게 하면 이벤트 루프가 블로킹됨
    time.sleep(1)  # ❌
    return requests.get("https://api.example.com")  # ❌

# ❌ DON'T: 예외 처리 없는 비동기 작업
async def bad_no_error_handling():
    # 예외가 발생하면 전체 작업이 중단됨
    results = await asyncio.gather(*tasks)  # ❌
    return results
```

### **✅ DO: 올바른 비동기 패턴**
```python
# ✅ DO: 실제 비동기 작업 사용
async def good_async_operation():
    async with aiohttp.ClientSession() as session:
        async with session.get("https://api.example.com") as response:
            return await response.json()

# ✅ DO: 비동기 sleep 사용
async def good_async_delay():
    await asyncio.sleep(1)  # ✅
    return await good_async_operation()

# ✅ DO: 예외 처리 포함
async def good_error_handling():
    try:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        return [r for r in results if not isinstance(r, Exception)]
    except Exception as e:
        logger.error(f"Batch operation failed: {e}")
        return []
```

## 테스트 패턴

### **비동기 테스트**
```python
# ✅ DO: 비동기 함수 테스트
@pytest.mark.asyncio
async def test_async_processing():
    """비동기 처리 함수 테스트."""
    files = [create_test_file() for _ in range(5)]
    
    results = await process_files_async(files)
    
    assert len(results) == 5
    assert all(isinstance(r, ProcessedFile) for r in results)
```

## 관련 룰 참조

- **에러 처리**: [error_handling.mdc](mdc:.cursor/rules/error_handling.mdc)
- **로깅**: [logging.mdc](mdc:.cursor/rules/logging.mdc)
- **테스트**: [testing.mdc](mdc:.cursor/rules/testing.mdc)
- **성능**: [performance.mdc](mdc:.cursor/rules/performance.mdc)