---
description: Structured logging system and log management patterns guide
globs: src/utils/logger.py, src/core/logging_utils.py, **/*log*.py, **/*monitor*.py
alwaysApply: false
---

# 로깅 시스템 패턴 가이드

## 핵심 원칙

- **구조화된 로깅**: JSON 포맷으로 구조화된 로그 사용
- **로그 레벨 일관성**: 적절한 로그 레벨 사용
- **성능 고려**: 로깅이 성능에 미치는 영향 최소화
- **보안**: 민감한 정보 로깅 방지

## 로깅 설정

### **AniVault 특화 로깅 구성**
```python
# ✅ DO: AniVault 표준 로깅 설정 (UTF-8 강제, 레벨별 분리)
import logging
import logging.handlers
from pathlib import Path
from datetime import datetime

def setup_anivault_logging(
    log_dir: Path = Path("logs"),
    debug_enabled: bool = False,
    environment: str = "production"
) -> None:
    """AniVault 로깅 시스템 초기화 - UTF-8 강제, 레벨별 파일 분리."""

    # 로그 디렉토리 생성 (UTF-8 환경)
    log_dir.mkdir(exist_ok=True)

    # 루트 로거 설정
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG if debug_enabled else logging.INFO)

    # 기존 핸들러 제거
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)

    # 콘솔 핸들러 (UTF-8 강제)
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    console_handler.setFormatter(console_formatter)
    root_logger.addHandler(console_handler)

    # AniVault 특화 파일 핸들러들 (개발 계획서 기준)
    handlers = [
        # INFO/DEBUG 로그
        ("app_info.log", logging.INFO, "INFO/DEBUG 로그"),
        # WARNING 로그
        ("app_warn.log", logging.WARNING, "WARNING 로그"),
        # ERROR/CRITICAL 로그
        ("app_error.log", logging.ERROR, "ERROR/CRITICAL 로그"),
        # 네트워크 관련 로그
        ("network.log", logging.INFO, "TMDB API 요청/응답 로그"),
        # 파이프라인 로그
        ("pipeline.log", logging.INFO, "스캔/파싱/매칭 단계별 이벤트 로그")
    ]

    for filename, level, description in handlers:
        handler = logging.handlers.TimedRotatingFileHandler(
            log_dir / filename,
            when='midnight',  # 일단위 회전
            interval=1,
            backupCount=7,  # 7일 보존
            encoding="utf-8",  # UTF-8 강제
            utc=True  # UTC 기준
        )
        handler.setLevel(level)

        # JSON 포맷터 적용
        json_formatter = AniVaultJSONFormatter()
        handler.setFormatter(json_formatter)

        # 특정 로거에만 적용
        if "network" in filename:
            network_logger = logging.getLogger("network")
            network_logger.addHandler(handler)
            network_logger.setLevel(level)
        elif "pipeline" in filename:
            pipeline_logger = logging.getLogger("pipeline")
            pipeline_logger.addHandler(handler)
            pipeline_logger.setLevel(level)
        else:
            root_logger.addHandler(handler)
```

### **AniVault JSON 포맷터**
```python
# ✅ DO: AniVault 구조화된 JSON 로깅 (UTF-8 전제)
import json
from datetime import datetime
from typing import Any, Dict
import threading

class AniVaultJSONFormatter(logging.Formatter):
    """AniVault JSON 포맷 로그 포매터 - UTF-8 전제, 스레드 정보 포함."""

    def format(self, record: logging.LogRecord) -> str:
        """로그 레코드를 JSON으로 포맷."""
        log_entry = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
            "thread": threading.current_thread().name,
            "thread_id": threading.get_ident(),
        }

        # 예외 정보 추가
        if record.exc_info:
            log_entry["exception"] = self.formatException(record.exc_info)

        # AniVault 특화 컨텍스트 정보
        if hasattr(record, 'context'):
            log_entry["context"] = record.context

        # TMDB API 관련 정보
        if hasattr(record, 'tmdb_request'):
            log_entry["tmdb_request"] = record.tmdb_request

        # 파일 처리 관련 정보
        if hasattr(record, 'file_processing'):
            log_entry["file_processing"] = record.file_processing

        # 파이프라인 단계 정보
        if hasattr(record, 'pipeline_stage'):
            log_entry["pipeline_stage"] = record.pipeline_stage

        return json.dumps(log_entry, ensure_ascii=False, separators=(',', ':'))
```

## 로깅 유틸리티

### **구조화된 로깅 함수**
```python
# ✅ DO: 일관된 로깅 유틸리티
def log_operation_error(
    operation_name: str,
    error: Exception,
    additional_context: str | None = None,
    *,
    level: int = logging.ERROR,
    exc_info: bool = False,
) -> None:
    """작업 에러 로깅."""
    context_msg = f" - {additional_context}" if additional_context else ""
    logger.log(
        level,
        f"Failed to {operation_name}: {error}{context_msg}",
        exc_info=exc_info,
        extra={"context": {"operation": operation_name, "error_type": type(error).__name__}}
    )

def log_database_error(
    operation_name: str,
    error: Exception,
    table_name: str | None = None
) -> None:
    """데이터베이스 에러 로깅."""
    table_info = f" (table: {table_name})" if table_name else ""
    logger.error(
        f"Database error in {operation_name}{table_info}: {error}",
        extra={"context": {"operation": operation_name, "table": table_name}}
    )

def log_performance_metric(
    operation_name: str,
    duration: float,
    additional_metrics: Dict[str, Any] | None = None
) -> None:
    """성능 메트릭 로깅."""
    metrics = {
        "operation": operation_name,
        "duration_seconds": duration,
        **(additional_metrics or {})
    }
    logger.info(
        f"Performance metric: {operation_name} took {duration:.3f}s",
        extra={"context": metrics}
    )
```

## 로그 레벨 가이드라인

### **로그 레벨 사용법**
```python
# ✅ DO: 적절한 로그 레벨 사용
logger.debug("Detailed debugging information")  # 개발 중 디버깅
logger.info("General information about program execution")  # 일반 정보
logger.warning("Something unexpected happened, but program continues")  # 경고
logger.error("A serious error occurred, but program can continue")  # 에러
logger.critical("A very serious error occurred, program may stop")  # 치명적 에러

# ✅ DO: 컨텍스트 정보 포함
logger.info(
    "File processed successfully",
    extra={"context": {"file_path": str(file_path), "file_size": file_size}}
)

logger.warning(
    "API rate limit approaching",
    extra={"context": {"current_requests": count, "limit": limit}}
)
```

## 성능 최적화

### **조건부 로깅**
```python
# ✅ DO: 성능을 고려한 로깅
def log_debug_if_enabled(message: str, **kwargs: Any) -> None:
    """디버그 로깅이 활성화된 경우에만 로깅."""
    if logger.isEnabledFor(logging.DEBUG):
        logger.debug(message, extra={"context": kwargs})

def log_expensive_operation(operation_name: str, data: Any) -> None:
    """비용이 큰 로깅 작업 최적화."""
    if logger.isEnabledFor(logging.DEBUG):
        # 데이터 크기가 클 경우 요약만 로깅
        if isinstance(data, (list, dict)) and len(str(data)) > 1000:
            summary = f"{type(data).__name__} with {len(data)} items"
            logger.debug(f"{operation_name}: {summary}")
        else:
            logger.debug(f"{operation_name}: {data}")
```

### **비동기 로깅**
```python
# ✅ DO: 비동기 로깅 (필요한 경우)
import asyncio
from concurrent.futures import ThreadPoolExecutor

class AsyncLogHandler:
    """비동기 로깅 핸들러."""

    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=1)

    async def log_async(self, level: int, message: str, **kwargs: Any) -> None:
        """비동기 로깅."""
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(
            self.executor,
            logger.log,
            level,
            message,
            extra={"context": kwargs}
        )
```

## 보안 고려사항

### **민감한 정보 보호**
```python
# ✅ DO: 민감한 정보 마스킹
def mask_sensitive_data(data: Dict[str, Any]) -> Dict[str, Any]:
    """민감한 정보를 마스킹."""
    sensitive_keys = {'password', 'api_key', 'token', 'secret'}
    masked_data = data.copy()

    for key in sensitive_keys:
        if key in masked_data:
            masked_data[key] = "***MASKED***"

    return masked_data

def log_with_sensitive_data_protection(message: str, data: Dict[str, Any]) -> None:
    """민감한 데이터 보호 로깅."""
    safe_data = mask_sensitive_data(data)
    logger.info(message, extra={"context": safe_data})
```

## 모니터링 및 메트릭

### **로깅 메트릭 수집**
```python
# ✅ DO: 로깅 메트릭 수집
class LoggingMetrics:
    """로깅 메트릭 수집기."""

    def __init__(self):
        self.error_count = 0
        self.warning_count = 0
        self.info_count = 0

    def increment_error(self) -> None:
        """에러 카운트 증가."""
        self.error_count += 1
        logger.info(
            "Error count updated",
            extra={"context": {"error_count": self.error_count}}
        )

    def get_metrics(self) -> Dict[str, int]:
        """현재 메트릭 반환."""
        return {
            "error_count": self.error_count,
            "warning_count": self.warning_count,
            "info_count": self.info_count
        }
```

## 안티패턴 및 금지사항

### **❌ DON'T: 잘못된 로깅 패턴**
```python
# ❌ DON'T: print 사용
def bad_logging():
    print("Error occurred")  # ❌ 로깅 시스템 사용하지 않음

# ❌ DON'T: 민감한 정보 로깅
def bad_sensitive_logging():
    logger.info(f"User login: {username}, password: {password}")  # ❌

# ❌ DON'T: 과도한 로깅
def bad_excessive_logging():
    for item in large_list:
        logger.debug(f"Processing item: {item}")  # ❌ 성능 저하

# ❌ DON'T: 일관성 없는 로그 포맷
def bad_inconsistent_logging():
    logger.info("User %s logged in", username)  # ❌
    logger.info(f"User {username} logged in")  # ❌
```

### **✅ DO: 올바른 로깅 패턴**
```python
# ✅ DO: 적절한 로깅 시스템 사용
def good_logging():
    logger.info("Operation completed successfully")

# ✅ DO: 민감한 정보 보호
def good_sensitive_logging():
    logger.info(
        "User login successful",
        extra={"context": {"username": username, "timestamp": datetime.now()}}
    )

# ✅ DO: 조건부 디버그 로깅
def good_conditional_logging():
    if logger.isEnabledFor(logging.DEBUG):
        logger.debug(f"Processing {len(items)} items")

    for item in items:
        # 중요한 정보만 로깅
        if item.has_error:
            logger.warning(f"Item processing failed: {item.id}")

# ✅ DO: 일관된 로그 포맷
def good_consistent_logging():
    logger.info("User %s logged in", username)
    logger.info("Operation %s completed", operation_name)
```

## 테스트 패턴

### **로깅 테스트**
```python
# ✅ DO: 로깅 테스트
def test_logging():
    """로깅 테스트."""
    with caplog.at_level(logging.INFO):
        logger.info("Test message")

    assert "Test message" in caplog.text
    assert caplog.records[0].levelname == "INFO"

def test_error_logging():
    """에러 로깅 테스트."""
    with caplog.at_level(logging.ERROR):
        try:
            raise ValueError("Test error")
        except ValueError as e:
            logger.error("Test error occurred", exc_info=True)

    assert "Test error occurred" in caplog.text
    assert "ValueError" in caplog.text
```

## 관련 룰 참조

- **에러 처리**: [error_handling.mdc](mdc:.cursor/rules/error_handling.mdc)
- **성능**: [performance.mdc](mdc:.cursor/rules/performance.mdc)
- **보안**: [security.mdc](mdc:.cursor/rules/security.mdc)
